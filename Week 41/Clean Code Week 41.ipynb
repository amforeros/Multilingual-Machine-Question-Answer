{"cells":[{"cell_type":"markdown","metadata":{"id":"XOwOS12oHJrx"},"source":["# Week 41 - Zero-shot Cross-lingual Evaluation"]},{"cell_type":"markdown","metadata":{"id":"0jDRMwJFG31h"},"source":["## 1. Setup"]},{"cell_type":"markdown","metadata":{"id":"S5n302rlIblM"},"source":["### 1.1. Libraries"]},{"cell_type":"markdown","metadata":{"id":"wjs9ApFwMrog"},"source":["#### 1.1.1. New Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54081,"status":"ok","timestamp":1698861858750,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"z08V_ZPyIecS","outputId":"53a33eb7-caff-43fb-b475-488c9c696d24"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.10.12\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n","Collecting datasets==2.2.1\n","  Downloading datasets-2.2.1-py3-none-any.whl (342 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.2/342.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting transformers==4.19.1\n","  Downloading transformers-4.19.1-py3-none-any.whl (4.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==2.2.1) (1.23.5)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.2.1) (9.0.0)\n","Collecting dill (from datasets==2.2.1)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.2.1) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.2.1) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.2.1) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.2.1) (3.4.1)\n","Collecting multiprocess (from datasets==2.2.1)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.2.1) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.2.1) (3.8.6)\n","Collecting huggingface-hub<1.0.0,>=0.1.0 (from datasets==2.2.1)\n","  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.2.1) (23.2)\n","Collecting responses<0.19 (from datasets==2.2.1)\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.1) (3.12.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.1) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.1) (2023.6.3)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers==4.19.1)\n","  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.2.1) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.2.1) (3.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.2.1) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.2.1) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.2.1) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.2.1) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.2.1) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.2.1) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.2.1) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.2.1) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.2.1) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.2.1) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.2.1) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets==2.2.1) (1.16.0)\n","Installing collected packages: tokenizers, dill, responses, multiprocess, huggingface-hub, transformers, datasets\n","Successfully installed datasets-2.2.1 dill-0.3.7 huggingface-hub-0.18.0 multiprocess-0.70.15 responses-0.18.0 tokenizers-0.12.1 transformers-4.19.1\n","Collecting bnlp-toolkit\n","  Downloading bnlp_toolkit-4.0.0-py3-none-any.whl (22 kB)\n","Collecting sentencepiece (from bnlp-toolkit)\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (4.3.2)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (1.11.3)\n","Collecting sklearn-crfsuite (from bnlp-toolkit)\n","  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (4.66.1)\n","Collecting ftfy (from bnlp-toolkit)\n","  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting emoji==1.7.0 (from bnlp-toolkit)\n","  Downloading emoji-1.7.0.tar.gz (175 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (2.31.0)\n","Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->bnlp-toolkit) (0.2.8)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->bnlp-toolkit) (6.4.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp-toolkit) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp-toolkit) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp-toolkit) (2023.6.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp-toolkit) (3.3.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp-toolkit) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp-toolkit) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp-toolkit) (2023.7.22)\n","Collecting python-crfsuite>=0.8.3 (from sklearn-crfsuite->bnlp-toolkit)\n","  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->bnlp-toolkit) (1.16.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->bnlp-toolkit) (0.9.0)\n","Building wheels for collected packages: emoji\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171033 sha256=381bbdf3b41b7589a80113ec5fa7d49ef2f7417b9c580bb529fd7dc9b667751e\n","  Stored in directory: /root/.cache/pip/wheels/31/8a/8c/315c9e5d7773f74b33d5ed33f075b49c6eaeb7cedbb86e2cf8\n","Successfully built emoji\n","Installing collected packages: sentencepiece, python-crfsuite, emoji, sklearn-crfsuite, ftfy, bnlp-toolkit\n","Successfully installed bnlp-toolkit-4.0.0 emoji-1.7.0 ftfy-6.1.1 python-crfsuite-0.9.9 sentencepiece-0.1.99 sklearn-crfsuite-0.3.6\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.19.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.18.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.12.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n","Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu118)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers[torch]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers[torch]) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->transformers[torch]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->transformers[torch]) (3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->transformers[torch]) (3.1.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->transformers[torch]) (2.1.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0->transformers[torch]) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0->transformers[torch]) (1.3.0)\n","Collecting bpemb\n","  Downloading bpemb-0.3.4-py3-none-any.whl (19 kB)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from bpemb) (4.3.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bpemb) (1.23.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bpemb) (2.31.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bpemb) (0.1.99)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bpemb) (4.66.1)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim->bpemb) (1.11.3)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->bpemb) (6.4.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (3.3.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (2023.7.22)\n","Installing collected packages: bpemb\n","Successfully installed bpemb-0.3.4\n","Collecting evaluate\n","  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n","Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.15)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.8.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3.post1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n","Installing collected packages: evaluate\n","Successfully installed evaluate-0.4.1\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.23.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.3)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=3f0146b95f32e64f19fc71a9023451f15d60815091fb4c578c4fba9c35b203f5\n","  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n","Collecting accelerate\n","  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.18.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.24.1\n"]}],"source":["!python --version      # you can also write shell commands in code blocks\n","!pip3 install nltk     # new libraries\n","!pip install datasets==2.2.1 transformers==4.19.1\n","!pip3 install bnlp-toolkit # Bengali_Tokenization\n","!pip3 install transformers[torch] # hyperparameters\n","!pip3 install bpemb # pretrain word embeddings\n","!pip install evaluate # evaluation\n","!pip install seqeval # special for our sequence model\n","!pip install accelerate # posprocessing\n"]},{"cell_type":"markdown","metadata":{"id":"VkrY-lgQMv-J"},"source":["#### 1.1.2. Load Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33770,"status":"ok","timestamp":1698861892516,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"nXG9jTstJqQZ","outputId":"68ce7357-91c0-413c-cf43-55947f470b78"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from datasets import load_dataset                       # library to import data from huggingface\n","from tqdm.notebook import tqdm                          # Check progress loop\n","import torch                                            # Torch objects\n","from torch.utils.data import DataLoader                 # Dataloader to iterate\n","from transformers import AutoTokenizer\n","from transformers import DataCollatorForTokenClassification\n","from torch.optim import AdamW\n","from transformers import AutoModelForTokenClassification\n","from transformers import AutoTokenizer, BertForSequenceClassification\n","from datasets import load_metric                                                     # Evaluation metric\n","# for padding in batches\n","from transformers import DataCollatorWithPadding\n","import numpy as np\n","from sklearn.metrics import f1_score\n","\n","\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"markdown","metadata":{"id":"zrOaTX15Ie8s"},"source":["### 1.2. Data"]},{"cell_type":"markdown","metadata":{"id":"xQkFMJpJKTij"},"source":["#### 1.2.1. Read Data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["72e481e3c1be47529e52c34df6a2593c","1108d5d3a66649e481f2ddf82ce811da","68d9f4b5b4774477817ce4e314c76670","64c64598ba6a4d3596d782b152f01b37","939eab7a92ea4335b412107c0db7b1c3","3e9f18c2dbb8498aaa245b0dac81e95d","8bd0089169f449aba57d724d2f4b5c9b","a93e40e9c5b84b44b6d507a3f1cdd76f","e2b023eaec954262b06deb55e745198d","37752254dc604e06ab5f9cb11a3805f1","3147f9a63b0d4eab95caca8ce33811fa","4b16517687384923ad7a6e14dd1d10ec","b050c6e337f14a60930d33780f3895c7","bee845de377a4585b1be893583537201","04331d08a3c84bd68eec03f877a0242e","6e06b39e956c435cb4b273e20b50f5de","1868226cbf0f4cbeaf6c4dd07b07fafe","a851ee6e72e7428ea59789e55224fe0d","0db7e52209fc48ce836af0fc882cc4d2","1ff51268d3e9401fadf9397c6cc23ff8","d8a4045cf2a24494b07f38d6e3c589dd","7177d00a257e4b66845114c76ad4198c","28ffa0c40b724540a8c15291dcbdf95a","b0df9c36bed045d0808a22b00c221258","f07a6c26a1254b23971a567066056557","ef95d4b96ddd40558f6c28479da456b6","7d1b4c73204c4f70b221bc40694cb27f","05783cf32c6b42d4b0428557191ecdc9","3c5554b2ce1c488f898f621b20a96793","25d6f5a6dea44638bc8af6b9e591fab5","2c292c3171c645abb90b41f74b912eb3","246f97f515044eed816274ffc6892e8d","e8cbecc4e26c4878854d1d3b453cccf8","78184cb68e4749eba08bb2acf87bc99d","7dc0037eebee4e0ba948972f15a37151","34292ae879ff42a8ac47b454c8e8f58e","35402735f0aa4bc9b75e4d026a341957","9008002bef4c4674a8d162a00ac5f9cc","9d3faab44c4c45ec8d3f6095271e90ec","e65c044095f64ad8a9f7b244ce33fe65","a61343fc1549444fa3c78cf519b520ee","70db074ab7d3418abcf86018a94bfdc3","691ae831a0a846b9836575ac6b138d36","1b6c607765e9463db27738ce6b260edd","6a2c8e713d0b43b2844b26e4b3c16ffe","2ce076baba8a4848a9bf34b7baba6c50","dfe3357fa68848c38cf1ec7a2d791b37","523734ee2de14215b7ad442849f1ff75","403dd3c7c8794f33b31b8af353af1f19","08fbd243439b4b638ee4fd62d2ac9704","fb6e89fe7dd2447aa6ea06bd1c9834ad","0780a3f208d640e7b4051f92fd8c7598","6d19cefd1ced485fa637c363700c2b63","12ff64b2010340bb8c323a19c14f673d","870bdbadc54a47cb8e251126c31e1ca6"]},"executionInfo":{"elapsed":7091,"status":"ok","timestamp":1698861899602,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"co_f3SN1J8FN","outputId":"68de9396-1f6e-4574-8461-281504c46746"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"72e481e3c1be47529e52c34df6a2593c","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/2.47k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["WARNING:datasets.builder:Using custom data configuration copenlu--nlp_course_tydiqa-42333912ea665dd0\n"]},{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset None/None (download: 75.43 MiB, generated: 131.78 MiB, post-processed: Unknown size, total: 207.21 MiB) to /root/.cache/huggingface/datasets/copenlu___parquet/copenlu--nlp_course_tydiqa-42333912ea665dd0/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4b16517687384923ad7a6e14dd1d10ec","version_major":2,"version_minor":0},"text/plain":["Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"28ffa0c40b724540a8c15291dcbdf95a","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/71.6M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"78184cb68e4749eba08bb2acf87bc99d","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/7.49M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6a2c8e713d0b43b2844b26e4b3c16ffe","version_major":2,"version_minor":0},"text/plain":["Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/copenlu___parquet/copenlu--nlp_course_tydiqa-42333912ea665dd0/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:datasets.builder:Using custom data configuration copenlu--nlp_course_tydiqa-42333912ea665dd0\n","WARNING:datasets.builder:Reusing dataset parquet (/root/.cache/huggingface/datasets/copenlu___parquet/copenlu--nlp_course_tydiqa-42333912ea665dd0/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"]}],"source":["languages = ['arabic', 'bengali', 'indonesian']\n","# load training dataset\n","datasets_train = load_dataset(\"copenlu/answerable_tydiqa\", split='train')\n","# load validation dataset\n","datasets_val = load_dataset(\"copenlu/answerable_tydiqa\", split='validation')"]},{"cell_type":"markdown","metadata":{"id":"kU3xBGtw_sOD"},"source":["#### 1.2.2. Transform Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v02YXbfc_vsm"},"outputs":[],"source":["def oracle(df_list_annotations = []):\n","  \"\"\"Check whether a question has an answer\"\"\"\n","  return [0 if x['answer_text'][0] == '' else 1 for x in df_list_annotations]\n","\n","# train\n","answerable_train = oracle(datasets_train['annotations'])\n","datasets_train = datasets_train.add_column(\"label\", answerable_train)\n","\n","# val\n","answerable_val = oracle(datasets_val['annotations'])\n","datasets_val = datasets_val.add_column(\"label\", answerable_val)"]},{"cell_type":"markdown","metadata":{"id":"VUDVf7zBaL-S"},"source":["## 2. Zero-shot Cross-lingual Evaluator"]},{"cell_type":"markdown","metadata":{"id":"xfOXaPOjvvig"},"source":["### 2.1. Sequence Labeler"]},{"cell_type":"markdown","metadata":{"id":"ZEMfGVtxmACX"},"source":["#### 2.1.1. From Bengali To Arabic"]},{"cell_type":"markdown","metadata":{"id":"-wp9hHE8GeS7"},"source":["##### 2.1.1.1 Filter Test Language"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["cb08edd6604a4060a0ccf5cf2bfe8dc3","7036d8b912484bc7aca2468a46f8ef2a","9c43a3f4a8bb4e14bdc6308fa342fce8","086f9e35732e4ee18903fbe778745af6","624eb490a7f34de09ba46b8f4caef1c2","15173cad831f43ef8e93e163eb4b3cff","aa19892a44e145aebdf40ad54f643bca","183097ab1bd449c897b6e38b04f21350","89db05ce60824ac8a1c1c7ab7de63db2","54aa64f1dbf34e2eae1a607c35fcf385","89ca2004a26f4b238c6d301c8c577429"]},"executionInfo":{"elapsed":1571,"status":"ok","timestamp":1698683998921,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"NZG8Q_TgFP1R","outputId":"67887394-f330-4470-e913-734f08f9ba6f"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:datasets.fingerprint:Parameter 'function'=<function <lambda> at 0x79d0abb315a0> of the transform datasets.arrow_dataset.Dataset.filter@2.0.1 couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cb08edd6604a4060a0ccf5cf2bfe8dc3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/14 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["language: arabic\n"]}],"source":["#parameters\n","language_ = languages[0]                          # filter language\n","#lstm_dim = 100                                    # dim neural lstm network\n","\n","# 0. Choose language\n","datasets_val_filter = datasets_val.filter(lambda dataset: dataset[\"language\"]==language_)\n","\n","print('language:', language_);"]},{"cell_type":"markdown","metadata":{"id":"gpmTCu0jGgiY"},"source":["##### 2.1.1.2. Tolkenize"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cFSwKbc8F30f"},"outputs":[],"source":["# call model (it was train with arabic, bengali, and indonesian)\n","# Name of the model\n","checkpoint = \"Week 39/ROBERTA SEQUENCE LABELER/MODELS/RoBERTa - BENGALI - SEQUENCE\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)                         # Number of binary options"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zPvXYZ8jGaZY"},"outputs":[],"source":["def get_train_features(samples):\n","  '''\n","  Tokenizes the text in the given samples, splittling inputs that are too long\n","  for our model across multiple features. Finds the token offsets of the answers,\n","  which ____ the labels for our inputs.\n","  '''\n","  answers = samples[\"annotations\"]\n","  start_positions = []\n","  end_positions = []\n","  y_sequence = []\n","\n","\n","  batch = tokenizer(\n","        samples['question_text'],\n","        samples['document_plaintext'],\n","        truncation=\"only_second\",\n","        stride=128,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","\n","  # Since one document might give several features if it is long\n","  # we need a mapping that shows what example each feature is associated with.\n","  sample_mapping = batch.pop('overflow_to_sample_mapping')\n","\n","  # This gives a map from token to character position in the original context\n","  # helps us computer start and end positions.\n","  offset_mapping = batch.pop('offset_mapping')\n","\n","  id_words_list_special_characters = batch.word_ids()\n","\n","  for i, offset in enumerate(offset_mapping):\n","      sample_idx = sample_mapping[i]                                                # id for identifying the row\n","      answer = answers[sample_idx]                                                  # answer associated with that id\n","      start_char = answer[\"answer_start\"][0]                                        # position character where answer starts\n","      end_char = answer[\"answer_start\"][0] + len(answer[\"answer_text\"][0])          # position character where answer finishes\n","      sequence_ids = batch.sequence_ids(i)                                         # identify question, answer, special characters (EOS, PADDING, etc)\n","\n","      # Find the start and end of the context\n","      idx = 0\n","      while sequence_ids[idx] != 1:                                                 # identify question characters or special characters\n","          idx += 1\n","      context_start = idx                                                           # identify beggining of context\n","      while sequence_ids[idx] == 1:\n","          idx += 1\n","      context_end = idx - 1                                                         # identify end of context\n","\n","      # If the answer is not fully inside the context, label is (0, 0)\n","      if offset[context_start][0] > start_char or offset[context_end][1] < end_char: # when truncating, if the first part of the context is after the answe or if the last part of the context is before the end of the answer\n","          start_positions.append(0)\n","          end_positions.append(0)\n","      else:\n","          # Otherwise it's the start and end token positions\n","          idx = context_start\n","          while idx <= context_end and offset[idx][0] <= start_char:                  # between the start of the answer\n","              idx += 1\n","          start_positions.append(idx - 1)\n","\n","          idx = context_end\n","          while idx >= context_start and offset[idx][1] >= end_char:                  # between the end of the answer\n","              idx -= 1\n","          end_positions.append(idx + 1)\n","\n","      y_sequence_loop = [0] * len(offset)\n","\n","      for index, token in enumerate(offset):\n","        if (start_positions[i]<=index)&(end_positions[i]>=index):\n","          y_sequence_loop[index] = 1\n","        if token == (0,0):\n","          y_sequence_loop[index] = -100\n","\n","      y_sequence.append(y_sequence_loop)\n","\n","  batch['labels']  = y_sequence\n","  return batch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["12ea9524c4d14f4089b0a702b29f12a8","6a789d9073d043e4a6e0c2194beab5c8","212dd362da114afbb1055598ee92b29f","462276a6ade24dcc84043c4e0121a738","afdd7fef7d6b4d4abd59da9106ce9764","ec3f4b64791f45788aa8fdcc617ed615","982fe576a0ff4bc591ce34558893cbe5","f4ba2b0b2bbe436eb9aed782f7ad1875","0dd4912b5ecd4364a1383b26545e4540","dc27b3a7bc514db4a292502506fbc716","cbcbebbf5482430e98f2d279e7cae09f"]},"executionInfo":{"elapsed":1975,"status":"ok","timestamp":1698684017198,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"ko2sgxiFGxjU","outputId":"6484a35a-8a31-4510-a23b-58ed533f02c9"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"12ea9524c4d14f4089b0a702b29f12a8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["val_dataset = datasets_val_filter.map(get_train_features, batched = True, remove_columns = datasets_val_filter.column_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1698684017199,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"0b3g3v1OIsmP","outputId":"782e32f5-e073-4fe2-d168-33bc84c084f0"},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['input_ids', 'attention_mask', 'labels'],\n","    num_rows: 1947\n","})"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["val_dataset"]},{"cell_type":"markdown","metadata":{"id":"MFYc-GVKHA3h"},"source":["##### 2.1.1.3. Load Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"smHuuWuZG6WI"},"outputs":[],"source":["data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n","\n","label_names = ['no answer', 'answer']\n","id2label = {'0':'no answer', '1': 'answer'}\n","label2id = {v: k for k, v in id2label.items()}\n","\n","model = AutoModelForTokenClassification.from_pretrained(checkpoint,\n","                                                       id2label=id2label,\n","                                                       label2id=label2id,).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1698684050563,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"_By7W3V5Iv7f","outputId":"c93dd9a8-7ad7-40fa-c60e-d2bbb9d9673e"},"outputs":[{"data":{"text/plain":["XLMRobertaForTokenClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"markdown","metadata":{"id":"S5M3SCbeH7e5"},"source":["##### 2.1.1.4. Evaluate the Train Model tn the Test Language"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":77,"referenced_widgets":["ebbbb0de7c7a4c7eacae39af149204b9","9360e6e92b2a4ffabc05aa9d504f9361","9bcd1b14cff74f6488e57c3feb7c7ccb","d38d10b41b4645a89aba5d4d16f10df6","d44fe148bbf4410fb32921f4d477f037","1bde098169f546a894ad91abc2be409a","34e9d7c892484196b6d9d249e21a3cf2","081ab5ca833048b6a5d1f3147e026330","102f030ca2a84d68b44da76462a203ba","535529964ebf497cbd7742fd9cc29283","33882578176d462cbca412a7276134fc"]},"executionInfo":{"elapsed":3718,"status":"ok","timestamp":1698684081989,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"S2hGzlmuIWSg","outputId":"ce806d3a-474c-4fc9-c359-b26f54d5621e"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ebbbb0de7c7a4c7eacae39af149204b9","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import evaluate\n","\n","metric = evaluate.load(\"seqeval\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AHniMOfyHUnl"},"outputs":[],"source":["import numpy as np\n","\n","\n","def compute_metrics(eval_preds):\n","    logits, labels = eval_preds\n","    predictions = np.argmax(logits, axis=-1)\n","\n","    # Remove ignored index (special tokens) and convert to labels\n","    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n","    true_predictions = [\n","        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n","    return {\n","        \"precision\": all_metrics[\"overall_precision\"],\n","        \"recall\": all_metrics[\"overall_recall\"],\n","        \"f1\": all_metrics[\"overall_f1\"],\n","        \"accuracy\": all_metrics[\"overall_accuracy\"],\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"esyx1DSVJyKc"},"outputs":[],"source":["def postprocess(predictions, labels):\n","    predictions = predictions.detach().cpu().clone().numpy()\n","    labels = labels.detach().cpu().clone().numpy()\n","\n","    # Remove ignored index (special tokens) and convert to labels\n","    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n","    true_predictions = [\n","        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    return true_labels, true_predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B5amsffMK5-v"},"outputs":[],"source":["val_dataloader = DataLoader(\n","    val_dataset, collate_fn=data_collator\n","    , batch_size=8\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cZbmWIJDMAWE"},"outputs":[],"source":["from accelerate import Accelerator\n","\n","accelerator = Accelerator()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":68385,"status":"ok","timestamp":1698684151469,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"ezsJzciEIfEq","outputId":"22f7bbef-18c9-4990-cd44-22c9f59e2129"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: no answer seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: answer seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"]},{"name":"stdout","output_type":"stream","text":["{'nswer': {'precision': 0.13760504201680673, 'recall': 0.27291666666666664, 'f1': 0.1829608938547486, 'number': 480}, 'o answer': {'precision': 0.45661942620117524, 'recall': 0.5447422680412372, 'f1': 0.4968033095148552, 'number': 2425}, 'overall_precision': 0.3776332899869961, 'overall_recall': 0.4998278829604131, 'overall_f1': 0.43022222222222223, 'overall_accuracy': 0.967001994465086}\n"]}],"source":["#progress_bar = tqdm(range(num_training_steps))\n","\n","for batch in val_dataloader:\n","    batch = {key: value.to(device) for key, value in batch.items()}\n","    with torch.no_grad():\n","        outputs = model(**batch)\n","\n","    predictions = outputs.logits.argmax(dim=-1)\n","    labels = batch[\"labels\"]\n","\n","    predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n","    labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n","\n","    predictions_gathered = accelerator.gather(predictions)\n","    labels_gathered = accelerator.gather(labels)\n","\n","    true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n","    metric.add_batch(predictions=true_predictions, references=true_labels)\n","\n","results = metric.compute()\n","print(results)\n","#   progress_bar.update(1)"]},{"cell_type":"markdown","metadata":{"id":"Q61ORRASmzFz"},"source":["#### 2.1.2. From Indonesian To Arabic"]},{"cell_type":"markdown","metadata":{"id":"3vGbPF31mzGR"},"source":["##### 2.1.2.1. Filter Test Language"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["284f66815fcb40cdb3b5de784ce97912","c444439042c246aba324ffc9c1cb92a1","08c192016fba4eb8a39f5b55ce52115d","a590e4cbe1c94d70a53caf29b596f10f","5d04c16bb3ff4dc59da0d94ce3548bb3","e40e63a0a2334a988135b25ade2477bc","7a2612d873834dfdb14b850ddb92a213","ee30095b576b498abaa518474154ad65","f4d51f1c181f4e96ab00e796b5cc4c84","129ee042daaf4f5f9c47ae4b754a31c7","d85aef39b79946fdbd13cba7d94769e6"]},"executionInfo":{"elapsed":686,"status":"ok","timestamp":1698684171000,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"B1cMm7FdPYYf","outputId":"326cd3db-5dea-4beb-bfed-e6524a3531dc"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"284f66815fcb40cdb3b5de784ce97912","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/14 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["language: arabic\n"]}],"source":["#parameters\n","language_ = languages[0]                          # filter language\n","#lstm_dim = 100                                    # dim neural lstm network\n","\n","# 0. Choose language\n","datasets_val_filter = datasets_val.filter(lambda dataset: dataset[\"language\"]==language_)\n","\n","print('language:', language_);"]},{"cell_type":"markdown","metadata":{"id":"IRNOE_AgmzGT"},"source":["##### 2.1.2.2. Tolkenize"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3X4rP6r8PYYj"},"outputs":[],"source":["from transformers import AutoTokenizer\n","\n","# call model (it was train with arabic, bengali, and indonesian)\n","# Name of the model\n","checkpoint = \"Week 39/ROBERTA SEQUENCE LABELER/MODELS/RoBERTa - INDONESIAN - SEQUENCE\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)                         # Number of binary options"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WsjMm67fPYYl"},"outputs":[],"source":["def get_train_features(samples):\n","  '''\n","  Tokenizes the text in the given samples, splittling inputs that are too long\n","  for our model across multiple features. Finds the token offsets of the answers,\n","  which ____ the labels for our inputs.\n","  '''\n","  answers = samples[\"annotations\"]\n","  start_positions = []\n","  end_positions = []\n","  y_sequence = []\n","\n","\n","  batch = tokenizer(\n","        samples['question_text'],\n","        samples['document_plaintext'],\n","        truncation=\"only_second\",\n","        stride=128,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","\n","  # Since one document might give several features if it is long\n","  # we need a mapping that shows what example each feature is associated with.\n","  sample_mapping = batch.pop('overflow_to_sample_mapping')\n","\n","  # This gives a map from token to character position in the original context\n","  # helps us computer start and end positions.\n","  offset_mapping = batch.pop('offset_mapping')\n","\n","  id_words_list_special_characters = batch.word_ids()\n","\n","  for i, offset in enumerate(offset_mapping):\n","      sample_idx = sample_mapping[i]                                                # id for identifying the row\n","      answer = answers[sample_idx]                                                  # answer associated with that id\n","      start_char = answer[\"answer_start\"][0]                                        # position character where answer starts\n","      end_char = answer[\"answer_start\"][0] + len(answer[\"answer_text\"][0])          # position character where answer finishes\n","      sequence_ids = batch.sequence_ids(i)                                         # identify question, answer, special characters (EOS, PADDING, etc)\n","\n","      # Find the start and end of the context\n","      idx = 0\n","      while sequence_ids[idx] != 1:                                                 # identify question characters or special characters\n","          idx += 1\n","      context_start = idx                                                           # identify beggining of context\n","      while sequence_ids[idx] == 1:\n","          idx += 1\n","      context_end = idx - 1                                                         # identify end of context\n","\n","      # If the answer is not fully inside the context, label is (0, 0)\n","      if offset[context_start][0] > start_char or offset[context_end][1] < end_char: # when truncating, if the first part of the context is after the answe or if the last part of the context is before the end of the answer\n","          start_positions.append(0)\n","          end_positions.append(0)\n","      else:\n","          # Otherwise it's the start and end token positions\n","          idx = context_start\n","          while idx <= context_end and offset[idx][0] <= start_char:                  # between the start of the answer\n","              idx += 1\n","          start_positions.append(idx - 1)\n","\n","          idx = context_end\n","          while idx >= context_start and offset[idx][1] >= end_char:                  # between the end of the answer\n","              idx -= 1\n","          end_positions.append(idx + 1)\n","\n","      y_sequence_loop = [0] * len(offset)\n","\n","      for index, token in enumerate(offset):\n","        if (start_positions[i]<=index)&(end_positions[i]>=index):\n","          y_sequence_loop[index] = 1\n","        if token == (0,0):\n","          y_sequence_loop[index] = -100\n","\n","      y_sequence.append(y_sequence_loop)\n","\n","  batch['labels']  = y_sequence\n","  return batch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["84b57975f74040abb6c08c9700ac9cc1","43e9cf3ab0ca47afa0b42c89f9357065","353b610d932c4336be2378fe3d0da42d","799c7107723349d8acbb70315f73422e","d017951fb697415bad39ec7e55cc9f6a","85792540d55f4ceca38020e7f16ef70d","e62facfda96a42ac8c9d96348e77f25d","9de6ba40899a4f0a807c0a19d958a86a","9551397def274153a6f8db708103a008","4dcb40ed578a4d7f954e6fe9d9a64fe4","b7fe50935a3648fe88f2a5464bbc08fe"]},"executionInfo":{"elapsed":1729,"status":"ok","timestamp":1698684186664,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"-LkFO46wPYYm","outputId":"027fd507-6410-4eb3-e3ab-2b7f502509bd"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"84b57975f74040abb6c08c9700ac9cc1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["val_dataset = datasets_val_filter.map(get_train_features, batched = True, remove_columns = datasets_val_filter.column_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1698684186665,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"txdCrcPNPYYn","outputId":"0fd76d11-52bc-4937-82a1-57a360f29089"},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['input_ids', 'attention_mask', 'labels'],\n","    num_rows: 1947\n","})"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["val_dataset"]},{"cell_type":"markdown","metadata":{"id":"GenDAacLmzGY"},"source":["##### 2.1.2.3. Load Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4iQGuVnlmzGZ"},"outputs":[],"source":["from transformers import DataCollatorForTokenClassification\n","\n","data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n","\n","from torch.optim import AdamW\n","from transformers import AutoModelForTokenClassification\n","\n","label_names = ['no answer', 'answer']\n","id2label = {'0':'no answer', '1': 'answer'}\n","label2id = {v: k for k, v in id2label.items()}\n","\n","model = AutoModelForTokenClassification.from_pretrained(checkpoint,\n","                                                       id2label=id2label,\n","                                                       label2id=label2id,).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1698684050563,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"newoJPFimzGa","outputId":"c93dd9a8-7ad7-40fa-c60e-d2bbb9d9673e"},"outputs":[{"data":{"text/plain":["XLMRobertaForTokenClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"markdown","metadata":{"id":"xdRaZ9avmzGb"},"source":["##### 2.1.2.4. Evaluate the Train Model tn the Test Language"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":77,"referenced_widgets":["ebbbb0de7c7a4c7eacae39af149204b9","9360e6e92b2a4ffabc05aa9d504f9361","9bcd1b14cff74f6488e57c3feb7c7ccb","d38d10b41b4645a89aba5d4d16f10df6","d44fe148bbf4410fb32921f4d477f037","1bde098169f546a894ad91abc2be409a","34e9d7c892484196b6d9d249e21a3cf2","081ab5ca833048b6a5d1f3147e026330","102f030ca2a84d68b44da76462a203ba","535529964ebf497cbd7742fd9cc29283","33882578176d462cbca412a7276134fc"]},"executionInfo":{"elapsed":3718,"status":"ok","timestamp":1698684081989,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"feJ1fEUrmzGc","outputId":"ce806d3a-474c-4fc9-c359-b26f54d5621e"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ebbbb0de7c7a4c7eacae39af149204b9","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import evaluate\n","\n","metric = evaluate.load(\"seqeval\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2SUnFZajmzGd"},"outputs":[],"source":["import numpy as np\n","\n","\n","def compute_metrics(eval_preds):\n","    logits, labels = eval_preds\n","    predictions = np.argmax(logits, axis=-1)\n","\n","    # Remove ignored index (special tokens) and convert to labels\n","    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n","    true_predictions = [\n","        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n","    return {\n","        \"precision\": all_metrics[\"overall_precision\"],\n","        \"recall\": all_metrics[\"overall_recall\"],\n","        \"f1\": all_metrics[\"overall_f1\"],\n","        \"accuracy\": all_metrics[\"overall_accuracy\"],\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7w6Vn9ppmzGe"},"outputs":[],"source":["def postprocess(predictions, labels):\n","    predictions = predictions.detach().cpu().clone().numpy()\n","    labels = labels.detach().cpu().clone().numpy()\n","\n","    # Remove ignored index (special tokens) and convert to labels\n","    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n","    true_predictions = [\n","        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    return true_labels, true_predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yxbxkaXUmzGf"},"outputs":[],"source":["val_dataloader = DataLoader(\n","    val_dataset, collate_fn=data_collator\n","    , batch_size=8\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dVUh8QMBmzGg"},"outputs":[],"source":["from accelerate import Accelerator\n","\n","accelerator = Accelerator()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":69083,"status":"ok","timestamp":1698684291727,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"7bEBHLLYPYYv","outputId":"c0736a93-c6ee-41c6-9b76-a2ab5a4bdfc1"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'nswer': {'precision': 0.3560924369747899, 'recall': 0.2848739495798319, 'f1': 0.31652661064425774, 'number': 1190}, 'o answer': {'precision': 0.6069823712409264, 'recall': 0.5613810741687979, 'f1': 0.5832918119913635, 'number': 3128}, 'overall_precision': 0.5448634590377113, 'overall_recall': 0.48517832329782307, 'overall_f1': 0.5132916819796643, 'overall_accuracy': 0.9762086203187498}\n"]}],"source":["#progress_bar = tqdm(range(num_training_steps))\n","\n","for batch in val_dataloader:\n","    batch = {key: value.to(device) for key, value in batch.items()}\n","    with torch.no_grad():\n","        outputs = model(**batch)\n","\n","    predictions = outputs.logits.argmax(dim=-1)\n","    labels = batch[\"labels\"]\n","\n","    predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n","    labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n","\n","    predictions_gathered = accelerator.gather(predictions)\n","    labels_gathered = accelerator.gather(labels)\n","\n","    true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n","    metric.add_batch(predictions=true_predictions, references=true_labels)\n","\n","results = metric.compute()\n","print(results)\n","#   progress_bar.update(1)"]},{"cell_type":"markdown","metadata":{"id":"fvnp7IqknhOf"},"source":["#### 2.1.3. From Indonesian To Bengali"]},{"cell_type":"markdown","metadata":{"id":"UcFf2oDbMO6s"},"source":["##### 2.1.3.1. Filter Test Language"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136,"referenced_widgets":["e3a700e49d4343ac954eb1f93ebaa336","da4dff462bec47109adb6b62ee14d591","2aac7ddebd904364819bf08bbf7885b5","a86baf6cf0a04d708fc4a553b4bd3033","106a361ff1314a48b2aa0238ce3d9844","c48eb6b296bf4bad8771207e2df95652","5466c04a300e4c0d8353e65e6dae5531","5107432d0ad841a5b5598af603ddcf3a","9f5189f4797742bcb763692db2e18b47","f02ad02ae1674401b12ab045c2320ca2","2f679a97bc0d4308b4a47441c6932875","cf1aaa4c73f2433bb0dc98b4963a5fb0","84246977786844f7adeddb5467378756","0a7833c587f2408bb30f79bf83be4daa","21b14d93a91f47948f3b2031caad79cd","067ddad1b5e345d79492e4c4c3bee8aa","10a0f4692d104064bdac02934a13f32d","30fdee57c21047bebee64875272c1626","d5fa34f925674f47aea83450e0361307","2ca070d6ae6b48eda3a067106f43d35c","57b106708c574102ae3ae2cd849f7901","2ae27e283b02471782949d6494b91fba"]},"executionInfo":{"elapsed":3122,"status":"ok","timestamp":1698677885816,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"DmDDa07hMO6t","outputId":"c5c71597-286c-4e31-b499-18ed03cecaaf"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:datasets.fingerprint:Parameter 'function'=<function <lambda> at 0x7ced4fb156c0> of the transform datasets.arrow_dataset.Dataset.filter@2.0.1 couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e3a700e49d4343ac954eb1f93ebaa336","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cf1aaa4c73f2433bb0dc98b4963a5fb0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/14 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["language: bengali\n"]}],"source":["#parameters\n","language_ = languages[1]                          # filter language\n","#lstm_dim = 100                                    # dim neural lstm network\n","\n","# 0. Choose language\n","datasets_val_filter = datasets_val.filter(lambda dataset: dataset[\"language\"]==language_)\n","\n","print('language:', language_);"]},{"cell_type":"markdown","metadata":{"id":"cMuQjO52MO6u"},"source":["##### 2.1.3.2. Tolkenize"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cIfZe7MfMO6u"},"outputs":[],"source":["from transformers import AutoTokenizer\n","\n","# call model (it was train with arabic, bengali, and indonesian)\n","# Name of the model\n","checkpoint = \"Week 39/ROBERTA SEQUENCE LABELER/MODELS/RoBERTa - INDONESIAN - SEQUENCE\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)                         # Number of binary options"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-FDYUxBRMO6u"},"outputs":[],"source":["def get_train_features(samples):\n","  '''\n","  Tokenizes the text in the given samples, splittling inputs that are too long\n","  for our model across multiple features. Finds the token offsets of the answers,\n","  which ____ the labels for our inputs.\n","  '''\n","  answers = samples[\"annotations\"]\n","  start_positions = []\n","  end_positions = []\n","  y_sequence = []\n","\n","\n","  batch = tokenizer(\n","        samples['question_text'],\n","        samples['document_plaintext'],\n","        truncation=\"only_second\",\n","        stride=128,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","\n","  # Since one document might give several features if it is long\n","  # we need a mapping that shows what example each feature is associated with.\n","  sample_mapping = batch.pop('overflow_to_sample_mapping')\n","\n","  # This gives a map from token to character position in the original context\n","  # helps us computer start and end positions.\n","  offset_mapping = batch.pop('offset_mapping')\n","\n","  id_words_list_special_characters = batch.word_ids()\n","\n","  for i, offset in enumerate(offset_mapping):\n","      sample_idx = sample_mapping[i]                                                # id for identifying the row\n","      answer = answers[sample_idx]                                                  # answer associated with that id\n","      start_char = answer[\"answer_start\"][0]                                        # position character where answer starts\n","      end_char = answer[\"answer_start\"][0] + len(answer[\"answer_text\"][0])          # position character where answer finishes\n","      sequence_ids = batch.sequence_ids(i)                                         # identify question, answer, special characters (EOS, PADDING, etc)\n","\n","      # Find the start and end of the context\n","      idx = 0\n","      while sequence_ids[idx] != 1:                                                 # identify question characters or special characters\n","          idx += 1\n","      context_start = idx                                                           # identify beggining of context\n","      while sequence_ids[idx] == 1:\n","          idx += 1\n","      context_end = idx - 1                                                         # identify end of context\n","\n","      # If the answer is not fully inside the context, label is (0, 0)\n","      if offset[context_start][0] > start_char or offset[context_end][1] < end_char: # when truncating, if the first part of the context is after the answe or if the last part of the context is before the end of the answer\n","          start_positions.append(0)\n","          end_positions.append(0)\n","      else:\n","          # Otherwise it's the start and end token positions\n","          idx = context_start\n","          while idx <= context_end and offset[idx][0] <= start_char:                  # between the start of the answer\n","              idx += 1\n","          start_positions.append(idx - 1)\n","\n","          idx = context_end\n","          while idx >= context_start and offset[idx][1] >= end_char:                  # between the end of the answer\n","              idx -= 1\n","          end_positions.append(idx + 1)\n","\n","      y_sequence_loop = [0] * len(offset)\n","\n","      for index, token in enumerate(offset):\n","        if (start_positions[i]<=index)&(end_positions[i]>=index):\n","          y_sequence_loop[index] = 1\n","        if token == (0,0):\n","          y_sequence_loop[index] = -100\n","\n","      y_sequence.append(y_sequence_loop)\n","\n","  batch['labels']  = y_sequence\n","  return batch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["e15e80c065704862832f3b170b48c4d5","f00e23c07d654bae8cd9bed93a48406c","dfa0d46df05a43249343d61c4dfec92e","34421449851b44d2b6f75021c760912b","937c08d0473f4880bd58cce4d66965db","fd09dd0ab9f542d3a854984cf89a4b12","7736ac0c6be34a82939e309d7ecbcba8","3ed76eec12d743f69a36d10ad9c9c275","92c0b99711a04083a851e8fffae52249","0f47c1aecd0448fe9b33eb0e626bb6c8","2ce8df6b3eaf47f0a34e6fa6d0dfd881"]},"executionInfo":{"elapsed":621,"status":"ok","timestamp":1698678155844,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"Dlb4mEu9MO6v","outputId":"0eafc26e-bec8-4fb1-ba37-9a724fff4350"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e15e80c065704862832f3b170b48c4d5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["val_dataset = datasets_val_filter.map(get_train_features, batched = True, remove_columns = datasets_val_filter.column_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":238,"status":"ok","timestamp":1698678624157,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"4CNTJFh0MO6v","outputId":"997655c9-ac3d-40db-c0de-20302ee807df"},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['input_ids', 'attention_mask', 'labels'],\n","    num_rows: 233\n","})"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["val_dataset"]},{"cell_type":"markdown","metadata":{"id":"XUozuRMFMO6v"},"source":["##### 2.1.3.3. Load Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zxzYWfB5MO6w"},"outputs":[],"source":["from transformers import DataCollatorForTokenClassification\n","\n","data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n","\n","from torch.optim import AdamW\n","from transformers import AutoModelForTokenClassification\n","\n","label_names = ['no answer', 'answer']\n","id2label = {'0':'no answer', '1': 'answer'}\n","label2id = {v: k for k, v in id2label.items()}\n","\n","model = AutoModelForTokenClassification.from_pretrained(checkpoint,\n","                                                       id2label=id2label,\n","                                                       label2id=label2id,)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1698678637637,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"1Hqlfk44MO6w","outputId":"7be01082-34d9-4276-fe92-cd84e818f025"},"outputs":[{"data":{"text/plain":["XLMRobertaForTokenClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"markdown","metadata":{"id":"VQUVttF3MO6w"},"source":["##### 2.1.3.4. Evaluate the Train Model tn the Test Language"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["2122d79dcdae436ca3d64aa70d0b6223","f4ffccb79aab4a419286155bee84b10d","807cd1583d984b9582f40714a150e9b3","eeeddf3a22dc4ef4b21275e6c7cda2ac","6390fd3093924033b904c9a47b59cf7f","ebc539b45ac34ff6a72c9ecf14077778","107c04a048a44b068904fc3bad9e55a8","1463b4df6be04bfca79c79f4c17e5649","afeae25de80147cdae5fc895cec2e4e6","2f878ba10d0b424db2166d8cbcf2e19c","783691165e714f22996a19dd298bd70b"]},"executionInfo":{"elapsed":2680,"status":"ok","timestamp":1698678544883,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"hNKCyIMQMO6x","outputId":"b66d230c-b1b3-4a98-aeca-371f20a72d63"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2122d79dcdae436ca3d64aa70d0b6223","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import evaluate\n","\n","metric = evaluate.load(\"seqeval\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f1mdEfeeMO6x"},"outputs":[],"source":["import numpy as np\n","\n","\n","def compute_metrics(eval_preds):\n","    logits, labels = eval_preds\n","    predictions = np.argmax(logits, axis=-1)\n","\n","    # Remove ignored index (special tokens) and convert to labels\n","    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n","    true_predictions = [\n","        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n","    return {\n","        \"precision\": all_metrics[\"overall_precision\"],\n","        \"recall\": all_metrics[\"overall_recall\"],\n","        \"f1\": all_metrics[\"overall_f1\"],\n","        \"accuracy\": all_metrics[\"overall_accuracy\"],\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9xI_m1GMMO6x"},"outputs":[],"source":["def postprocess(predictions, labels):\n","    predictions = predictions.detach().cpu().clone().numpy()\n","    labels = labels.detach().cpu().clone().numpy()\n","\n","    # Remove ignored index (special tokens) and convert to labels\n","    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n","    true_predictions = [\n","        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    return true_labels, true_predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"szxYZNuxMO6x"},"outputs":[],"source":["val_dataloader = DataLoader(\n","    val_dataset, collate_fn=data_collator, batch_size=8\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zB95QRPuMO6y"},"outputs":[],"source":["from accelerate import Accelerator\n","\n","accelerator = Accelerator()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":317557,"status":"ok","timestamp":1698680151061,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"UvaYwUocMO6y","outputId":"63e8707e-5d8d-4298-a6fe-a58d8db7bbef"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: no answer seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: answer seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"]},{"name":"stdout","output_type":"stream","text":["{'nswer': {'precision': 0.125, 'recall': 0.2222222222222222, 'f1': 0.16, 'number': 63}, 'o answer': {'precision': 0.4492753623188406, 'recall': 0.5236486486486487, 'f1': 0.483619344773791, 'number': 296}, 'overall_precision': 0.36980306345733044, 'overall_recall': 0.47075208913649025, 'overall_f1': 0.41421568627450983, 'overall_accuracy': 0.9863143688583358}\n"]}],"source":["#progress_bar = tqdm(range(num_training_steps))\n","\n","for batch in val_dataloader:\n","    with torch.no_grad():\n","        outputs = model(**batch)\n","\n","    predictions = outputs.logits.argmax(dim=-1)\n","    labels = batch[\"labels\"]\n","\n","    predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n","    labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n","\n","    predictions_gathered = accelerator.gather(predictions)\n","    labels_gathered = accelerator.gather(labels)\n","\n","    true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n","    metric.add_batch(predictions=true_predictions, references=true_labels)\n","\n","results = metric.compute()\n","print(results)\n","#   progress_bar.update(1)"]},{"cell_type":"markdown","metadata":{"id":"G8MPA7dPntAl"},"source":["#### 2.1.4. From Arabic to Bengali"]},{"cell_type":"markdown","metadata":{"id":"0N62TwnGPYYe"},"source":["##### 2.1.4.1. Filter Test Language"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["d31dd1f7275a4662aaa9704708aab11b","26f16a10e9f842ee872598084ab62ecf","fb044ef8282d4ffdb9660d818ee4ac92","ec7a6676b2934dfdbc37be8ba7fa4dba","c61c05a793584911a46c1c71984bd1e7","a6a8166452a04384903ed3cb327107bc","b13d30bc87d84351a94ee728bfec373f","d35a798a2a5a4dc19fad13060b3480c2","c97e615641d34da2b3c3f8965b3a48fa","7ec746a4826a406287b614a5aa8c6e97","e8bdc13e325a493facaa9dd9184c89fb"]},"executionInfo":{"elapsed":804,"status":"ok","timestamp":1698680473931,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"9r6jHyQSMtQI","outputId":"d744928d-5d2c-4b42-f832-e2710066ddfa"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d31dd1f7275a4662aaa9704708aab11b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/14 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["language: bengali\n"]}],"source":["#parameters\n","language_ = languages[1]                          # filter language\n","#lstm_dim = 100                                    # dim neural lstm network\n","\n","# 0. Choose language\n","datasets_val_filter = datasets_val.filter(lambda dataset: dataset[\"language\"]==language_)\n","\n","print('language:', language_);"]},{"cell_type":"markdown","metadata":{"id":"NAWkAh24PYYi"},"source":["##### 2.1.4.2. Tolkenize"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-_lvKtQOMtQI"},"outputs":[],"source":["from transformers import AutoTokenizer\n","\n","# call model (it was train with arabic, bengali, and indonesian)\n","# Name of the model\n","checkpoint = \"Week 39/ROBERTA SEQUENCE LABELER/MODELS/RoBERTa - ARABIC - SEQUENCE\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)                         # Number of binary options"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XtmuxLzoMtQJ"},"outputs":[],"source":["def get_train_features(samples):\n","  '''\n","  Tokenizes the text in the given samples, splittling inputs that are too long\n","  for our model across multiple features. Finds the token offsets of the answers,\n","  which ____ the labels for our inputs.\n","  '''\n","  answers = samples[\"annotations\"]\n","  start_positions = []\n","  end_positions = []\n","  y_sequence = []\n","\n","\n","  batch = tokenizer(\n","        samples['question_text'],\n","        samples['document_plaintext'],\n","        truncation=\"only_second\",\n","        stride=128,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","\n","  # Since one document might give several features if it is long\n","  # we need a mapping that shows what example each feature is associated with.\n","  sample_mapping = batch.pop('overflow_to_sample_mapping')\n","\n","  # This gives a map from token to character position in the original context\n","  # helps us computer start and end positions.\n","  offset_mapping = batch.pop('offset_mapping')\n","\n","  id_words_list_special_characters = batch.word_ids()\n","\n","  for i, offset in enumerate(offset_mapping):\n","      sample_idx = sample_mapping[i]                                                # id for identifying the row\n","      answer = answers[sample_idx]                                                  # answer associated with that id\n","      start_char = answer[\"answer_start\"][0]                                        # position character where answer starts\n","      end_char = answer[\"answer_start\"][0] + len(answer[\"answer_text\"][0])          # position character where answer finishes\n","      sequence_ids = batch.sequence_ids(i)                                         # identify question, answer, special characters (EOS, PADDING, etc)\n","\n","      # Find the start and end of the context\n","      idx = 0\n","      while sequence_ids[idx] != 1:                                                 # identify question characters or special characters\n","          idx += 1\n","      context_start = idx                                                           # identify beggining of context\n","      while sequence_ids[idx] == 1:\n","          idx += 1\n","      context_end = idx - 1                                                         # identify end of context\n","\n","      # If the answer is not fully inside the context, label is (0, 0)\n","      if offset[context_start][0] > start_char or offset[context_end][1] < end_char: # when truncating, if the first part of the context is after the answe or if the last part of the context is before the end of the answer\n","          start_positions.append(0)\n","          end_positions.append(0)\n","      else:\n","          # Otherwise it's the start and end token positions\n","          idx = context_start\n","          while idx <= context_end and offset[idx][0] <= start_char:                  # between the start of the answer\n","              idx += 1\n","          start_positions.append(idx - 1)\n","\n","          idx = context_end\n","          while idx >= context_start and offset[idx][1] >= end_char:                  # between the end of the answer\n","              idx -= 1\n","          end_positions.append(idx + 1)\n","\n","      y_sequence_loop = [0] * len(offset)\n","\n","      for index, token in enumerate(offset):\n","        if (start_positions[i]<=index)&(end_positions[i]>=index):\n","          y_sequence_loop[index] = 1\n","        if token == (0,0):\n","          y_sequence_loop[index] = -100\n","\n","      y_sequence.append(y_sequence_loop)\n","\n","  batch['labels']  = y_sequence\n","  return batch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["3f396b6fdff5410583c177f58fa63507","c5d488d56dbf40eba6a1dc3711dc77b1","87213be85b854ca18b603ce29b6e36b8","37926b910c214bbda7ee376480fdb853","6eb518e9cda84035b4330ce31cf03b47","7dd7299881a743868092393a4fc5d578","c37ba8fd53c34c48a1c4a36a0f6273b5","fc69a604a5bd4c02a891773044ed268f","b54ecbe88f814c5e8ba4bce728afe6c1","f54e0e1b8114464c9e4f096601b7bd1e","52d0a9e2822e4476b32b829da1c6992d"]},"executionInfo":{"elapsed":354,"status":"ok","timestamp":1698680484142,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"4OhMlgjuMtQJ","outputId":"161bdb6c-4fee-4620-cac5-5ac464cf3503"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3f396b6fdff5410583c177f58fa63507","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["val_dataset = datasets_val_filter.map(get_train_features, batched = True, remove_columns = datasets_val_filter.column_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1698680484143,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"m2sAIdJRMtQJ","outputId":"352e8a98-0bd9-45c6-a114-aa093f6c93ab"},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['input_ids', 'attention_mask', 'labels'],\n","    num_rows: 233\n","})"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["val_dataset"]},{"cell_type":"markdown","metadata":{"id":"HUsVBScuPYYo"},"source":["##### 2.1.4.3. Load Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yiw6iuUXPYYp"},"outputs":[],"source":["from transformers import DataCollatorForTokenClassification\n","\n","data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n","\n","from torch.optim import AdamW\n","from transformers import AutoModelForTokenClassification\n","\n","label_names = ['no answer', 'answer']\n","id2label = {'0':'no answer', '1': 'answer'}\n","label2id = {v: k for k, v in id2label.items()}\n","\n","model = AutoModelForTokenClassification.from_pretrained(checkpoint,\n","                                                       id2label=id2label,\n","                                                       label2id=label2id,)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":356,"status":"ok","timestamp":1698680642646,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"gqVSJSvkPYYr","outputId":"b75b54d0-e116-4f96-de44-902549bd67db"},"outputs":[{"data":{"text/plain":["XLMRobertaForTokenClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"markdown","metadata":{"id":"baXV2NRSPYYr"},"source":["##### 2.1.4.4. Evaluate the Train Model tn the Test Language"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YN-RrLU8PYYs"},"outputs":[],"source":["import evaluate\n","\n","metric = evaluate.load(\"seqeval\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k1bvBHQRPYYt"},"outputs":[],"source":["import numpy as np\n","\n","\n","def compute_metrics(eval_preds):\n","    logits, labels = eval_preds\n","    predictions = np.argmax(logits, axis=-1)\n","\n","    # Remove ignored index (special tokens) and convert to labels\n","    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n","    true_predictions = [\n","        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n","    return {\n","        \"precision\": all_metrics[\"overall_precision\"],\n","        \"recall\": all_metrics[\"overall_recall\"],\n","        \"f1\": all_metrics[\"overall_f1\"],\n","        \"accuracy\": all_metrics[\"overall_accuracy\"],\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z27bSUPAPYYt"},"outputs":[],"source":["def postprocess(predictions, labels):\n","    predictions = predictions.detach().cpu().clone().numpy()\n","    labels = labels.detach().cpu().clone().numpy()\n","\n","    # Remove ignored index (special tokens) and convert to labels\n","    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n","    true_predictions = [\n","        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    return true_labels, true_predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S9BWMkfVPYYu"},"outputs":[],"source":["val_dataloader = DataLoader(\n","    val_dataset, collate_fn=data_collator, batch_size=8\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1I33nUNqPYYu"},"outputs":[],"source":["from accelerate import Accelerator\n","\n","accelerator = Accelerator()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":332091,"status":"ok","timestamp":1698681003048,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"5Lthao87MtQL","outputId":"01a75277-0d3a-4d07-e0ef-04de797c6204"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'nswer': {'precision': 0.20535714285714285, 'recall': 0.3026315789473684, 'f1': 0.24468085106382978, 'number': 76}, 'o answer': {'precision': 0.46956521739130436, 'recall': 0.5242718446601942, 'f1': 0.4954128440366973, 'number': 309}, 'overall_precision': 0.4048140043763676, 'overall_recall': 0.4805194805194805, 'overall_f1': 0.43942992874109266, 'overall_accuracy': 0.9845641263548564}\n"]}],"source":["#progress_bar = tqdm(range(num_training_steps))\n","\n","for batch in val_dataloader:\n","    with torch.no_grad():\n","        outputs = model(**batch)\n","\n","    predictions = outputs.logits.argmax(dim=-1)\n","    labels = batch[\"labels\"]\n","\n","    predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n","    labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n","\n","    predictions_gathered = accelerator.gather(predictions)\n","    labels_gathered = accelerator.gather(labels)\n","\n","    true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n","    metric.add_batch(predictions=true_predictions, references=true_labels)\n","\n","results = metric.compute()\n","print(results)\n","#   progress_bar.update(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T4_m7V6tPYYv"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"wXHtGCc-n0nT"},"source":["#### 2.1.5. From Bengali To Indonesian"]},{"cell_type":"markdown","metadata":{"id":"CJeJtnAyNWz5"},"source":["##### 2.1.5.1. Filter Test Language"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["937fb5ad3ebe4a0894030e451e0def0f","21941f28a0f844eca6f49ed23b983353","b97e5405203747babe4a20dece4c2fbc","32a092b863b443ea968076fb9fe9aa55","4fa8f1f622f94be689168d364bc99fea","2af188b3b3d641079058f71f9360f1f1","66dddc9ed29b486e87853c1e70b97367","ac9370e01db945209bcd644f2604db52","a04598dcc2b7422591dd0896546b9c84","d42d049944854aaabc95162f2b8b47f1","a407dc86f94243c88f818cf385883537"]},"executionInfo":{"elapsed":590,"status":"ok","timestamp":1698682509369,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"6QHdQNllNW0E","outputId":"998bc1e6-7f49-4db2-836b-343b005e91f4"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:datasets.fingerprint:Parameter 'function'=<function <lambda> at 0x7e7b9fe65ab0> of the transform datasets.arrow_dataset.Dataset.filter@2.0.1 couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"937fb5ad3ebe4a0894030e451e0def0f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/14 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["language: indonesian\n"]}],"source":["#parameters\n","language_ = languages[2]                          # filter language\n","#lstm_dim = 100                                    # dim neural lstm network\n","\n","# 0. Choose language\n","datasets_val_filter = datasets_val.filter(lambda dataset: dataset[\"language\"]==language_)\n","\n","print('language:', language_);"]},{"cell_type":"markdown","metadata":{"id":"LbD7tvk_NW0E"},"source":["##### 2.1.5.2. Tolkenize"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KT25sPmsNW0E"},"outputs":[],"source":["from transformers import AutoTokenizer\n","\n","# call model (it was train with arabic, bengali, and indonesian)\n","# Name of the model\n","checkpoint = \"Week 39/ROBERTA SEQUENCE LABELER/MODELS/RoBERTa - BENGALI - SEQUENCE\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)                         # Number of binary options"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HYxPVykiNW0E"},"outputs":[],"source":["def get_train_features(samples):\n","  '''\n","  Tokenizes the text in the given samples, splittling inputs that are too long\n","  for our model across multiple features. Finds the token offsets of the answers,\n","  which ____ the labels for our inputs.\n","  '''\n","  answers = samples[\"annotations\"]\n","  start_positions = []\n","  end_positions = []\n","  y_sequence = []\n","\n","\n","  batch = tokenizer(\n","        samples['question_text'],\n","        samples['document_plaintext'],\n","        truncation=\"only_second\",\n","        stride=128,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","\n","  # Since one document might give several features if it is long\n","  # we need a mapping that shows what example each feature is associated with.\n","  sample_mapping = batch.pop('overflow_to_sample_mapping')\n","\n","  # This gives a map from token to character position in the original context\n","  # helps us computer start and end positions.\n","  offset_mapping = batch.pop('offset_mapping')\n","\n","  id_words_list_special_characters = batch.word_ids()\n","\n","  for i, offset in enumerate(offset_mapping):\n","      sample_idx = sample_mapping[i]                                                # id for identifying the row\n","      answer = answers[sample_idx]                                                  # answer associated with that id\n","      start_char = answer[\"answer_start\"][0]                                        # position character where answer starts\n","      end_char = answer[\"answer_start\"][0] + len(answer[\"answer_text\"][0])          # position character where answer finishes\n","      sequence_ids = batch.sequence_ids(i)                                         # identify question, answer, special characters (EOS, PADDING, etc)\n","\n","      # Find the start and end of the context\n","      idx = 0\n","      while sequence_ids[idx] != 1:                                                 # identify question characters or special characters\n","          idx += 1\n","      context_start = idx                                                           # identify beggining of context\n","      while sequence_ids[idx] == 1:\n","          idx += 1\n","      context_end = idx - 1                                                         # identify end of context\n","\n","      # If the answer is not fully inside the context, label is (0, 0)\n","      if offset[context_start][0] > start_char or offset[context_end][1] < end_char: # when truncating, if the first part of the context is after the answe or if the last part of the context is before the end of the answer\n","          start_positions.append(0)\n","          end_positions.append(0)\n","      else:\n","          # Otherwise it's the start and end token positions\n","          idx = context_start\n","          while idx <= context_end and offset[idx][0] <= start_char:                  # between the start of the answer\n","              idx += 1\n","          start_positions.append(idx - 1)\n","\n","          idx = context_end\n","          while idx >= context_start and offset[idx][1] >= end_char:                  # between the end of the answer\n","              idx -= 1\n","          end_positions.append(idx + 1)\n","\n","      y_sequence_loop = [0] * len(offset)\n","\n","      for index, token in enumerate(offset):\n","        if (start_positions[i]<=index)&(end_positions[i]>=index):\n","          y_sequence_loop[index] = 1\n","        if token == (0,0):\n","          y_sequence_loop[index] = -100\n","\n","      y_sequence.append(y_sequence_loop)\n","\n","  batch['labels']  = y_sequence\n","  return batch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["d0120a2864bc4338982421cb04b99b50","905cede782964785a4120982b3122feb","24b841671e9e42579bbea8fcbb8cb0a5","ffe93bd50de945949c2dc6b8eee7d8e9","ba2cb8200d3d4df98314826206c5489c","2dbf045dde6c4c77b5de0ae3d905f00b","a967c04cacf24435936dbe6e1d83ac7e","6612057dd0a7412bb85b5ee810c050c1","05e1730813924a408b6df83c8337f395","1a70e7d2c9a34805aee27ba19051f665","2993c2efc80840a5926f60ec764a179d"]},"executionInfo":{"elapsed":1067,"status":"ok","timestamp":1698682524669,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"Iw1jZ2yvNW0F","outputId":"3ee329fa-ae76-4976-f8af-6e6100071ef1"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d0120a2864bc4338982421cb04b99b50","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["val_dataset = datasets_val_filter.map(get_train_features, batched = True, remove_columns = datasets_val_filter.column_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1698682525879,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"M1K6jcNENW0F","outputId":"b351e81f-9c49-47eb-c7d7-8de88e711215"},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['input_ids', 'attention_mask', 'labels'],\n","    num_rows: 1208\n","})"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["val_dataset"]},{"cell_type":"markdown","metadata":{"id":"0dwWsXPxNW0F"},"source":["##### 2.1.5.3. Load Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0v1slj9RNW0F"},"outputs":[],"source":["from transformers import DataCollatorForTokenClassification\n","\n","data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n","\n","from torch.optim import AdamW\n","from transformers import AutoModelForTokenClassification\n","\n","label_names = ['no answer', 'answer']\n","id2label = {'0':'no answer', '1': 'answer'}\n","label2id = {v: k for k, v in id2label.items()}\n","\n","model = AutoModelForTokenClassification.from_pretrained(checkpoint,\n","                                                       id2label=id2label,\n","                                                       label2id=label2id,).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":375,"status":"ok","timestamp":1698682980795,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"xGXKRP3_NW0G","outputId":"72a11d81-0931-4490-e25b-576bf07f34bc"},"outputs":[{"data":{"text/plain":["XLMRobertaForTokenClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"markdown","metadata":{"id":"hUVuYzIrNW0G"},"source":["##### 2.1.5.4. Evaluate the Train Model tn the Test Language"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":77,"referenced_widgets":["74c1865e7128419c8f0db519f9b246cd","05d7ec5ad72e4c61b2a7e43f7df4eb60","e6dabe27b6304064b44df55e5f172f9e","57b84821c0514fc7815aa24a0fd03bc8","f0d182e4fa6b4d8b94cdde41b3843644","b19d64515ad04c4f81d431daea2a63fb","71db47efd36d4ee29f069fe84265f603","5824fb4335654fb88ae5d658c30fabd8","79b8e339e4b4403d9187e5fa5ba5d82b","c3e77c5156394d51a9a3f765684831f5","79efe0513cf74078ac0a288045fb33ed"]},"executionInfo":{"elapsed":1901,"status":"ok","timestamp":1698682646037,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"KpkTW_0cNW0G","outputId":"70eb1f55-38f2-44bf-cd63-2f989f00215d"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"74c1865e7128419c8f0db519f9b246cd","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import evaluate\n","\n","metric = evaluate.load(\"seqeval\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uuhnjYTrNW0G"},"outputs":[],"source":["import numpy as np\n","\n","\n","def compute_metrics(eval_preds):\n","    logits, labels = eval_preds\n","    predictions = np.argmax(logits, axis=-1)\n","\n","    # Remove ignored index (special tokens) and convert to labels\n","    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n","    true_predictions = [\n","        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n","    return {\n","        \"precision\": all_metrics[\"overall_precision\"],\n","        \"recall\": all_metrics[\"overall_recall\"],\n","        \"f1\": all_metrics[\"overall_f1\"],\n","        \"accuracy\": all_metrics[\"overall_accuracy\"],\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DMLKrwnUNW0H"},"outputs":[],"source":["def postprocess(predictions, labels):\n","    predictions = predictions.detach().cpu().clone().numpy()\n","    labels = labels.detach().cpu().clone().numpy()\n","\n","    # Remove ignored index (special tokens) and convert to labels\n","    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n","    true_predictions = [\n","        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    return true_labels, true_predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xcob08y7NW0H"},"outputs":[],"source":["val_dataloader = DataLoader(\n","    val_dataset, collate_fn=data_collator\n","    , batch_size=8\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Puz945rNW0H"},"outputs":[],"source":["from accelerate import Accelerator\n","\n","accelerator = Accelerator()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45166,"status":"ok","timestamp":1698683419080,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"fO-0Ai_wNW0H","outputId":"1fd8a26c-67f9-401f-a71d-37849786afad"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: no answer seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: answer seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"]},{"name":"stdout","output_type":"stream","text":["{'nswer': {'precision': 0.15862068965517243, 'recall': 0.35384615384615387, 'f1': 0.21904761904761905, 'number': 325}, 'o answer': {'precision': 0.4375303840544482, 'recall': 0.5418422636965683, 'f1': 0.48413125336202256, 'number': 1661}, 'overall_precision': 0.3648454349388929, 'overall_recall': 0.5110775427995972, 'overall_f1': 0.42575503355704697, 'overall_accuracy': 0.9692545293282142}\n"]}],"source":["#progress_bar = tqdm(range(num_training_steps))\n","\n","for batch in val_dataloader:\n","    batch = {key: value.to(device) for key, value in batch.items()}\n","    with torch.no_grad():\n","        outputs = model(**batch)\n","\n","    predictions = outputs.logits.argmax(dim=-1)\n","    labels = batch[\"labels\"]\n","\n","    predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n","    labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n","\n","    predictions_gathered = accelerator.gather(predictions)\n","    labels_gathered = accelerator.gather(labels)\n","\n","    true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n","    metric.add_batch(predictions=true_predictions, references=true_labels)\n","\n","results = metric.compute()\n","print(results)\n","#   progress_bar.update(1)"]},{"cell_type":"markdown","metadata":{"id":"BguBSFC_oAAy"},"source":["#### 2.1.6. From Arabic To Indonesian"]},{"cell_type":"markdown","metadata":{"id":"dpwqMnOeOD4O"},"source":["##### 2.1.6.1. Filter Test Language"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["764e8a2940d9475ebd1ba53a6ff54e42","9b4398282e2b402f88ac1cdadd6b46bd","565c333ebda04516bf1bd7687ead9b03","c98a5fcd89a848e792ea5f2d2e49d2b0","17b08b02541e49a2af9b30aaaaee0015","2813bf14f1954b058426d92d3cf32023","cbde2c70eb674fa1a1a27d3f2c304c70","4bd715b5d09e42e6a6e03faa19af50ff","b95b4946911549d0a3bba9109d7379ec","7e5efbbc5be54cb9ba34e05738b26a2c","867cc4c956f24a7fa3bd0e6e5fd26356"]},"executionInfo":{"elapsed":761,"status":"ok","timestamp":1698683492212,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"DdK3bpLpOD4P","outputId":"9e14f779-9b82-4fd0-d3b5-a36f1f565617"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"764e8a2940d9475ebd1ba53a6ff54e42","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/14 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["language: indonesian\n"]}],"source":["#parameters\n","language_ = languages[2]                          # filter language\n","#lstm_dim = 100                                    # dim neural lstm network\n","\n","# 0. Choose language\n","datasets_val_filter = datasets_val.filter(lambda dataset: dataset[\"language\"]==language_)\n","\n","print('language:', language_);"]},{"cell_type":"markdown","metadata":{"id":"m7WrecSMOD4P"},"source":["##### 2.1.6.2. Tolkenize"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1uGRRwUqOD4Q"},"outputs":[],"source":["from transformers import AutoTokenizer\n","\n","# call model (it was train with arabic, bengali, and indonesian)\n","# Name of the model\n","checkpoint = \"Week 39/ROBERTA SEQUENCE LABELER/MODELS/RoBERTa - ARABIC - SEQUENCE\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)                         # Number of binary options"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"siNHHZFZOD4Q"},"outputs":[],"source":["def get_train_features(samples):\n","  '''\n","  Tokenizes the text in the given samples, splittling inputs that are too long\n","  for our model across multiple features. Finds the token offsets of the answers,\n","  which ____ the labels for our inputs.\n","  '''\n","  answers = samples[\"annotations\"]\n","  start_positions = []\n","  end_positions = []\n","  y_sequence = []\n","\n","\n","  batch = tokenizer(\n","        samples['question_text'],\n","        samples['document_plaintext'],\n","        truncation=\"only_second\",\n","        stride=128,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","\n","  # Since one document might give several features if it is long\n","  # we need a mapping that shows what example each feature is associated with.\n","  sample_mapping = batch.pop('overflow_to_sample_mapping')\n","\n","  # This gives a map from token to character position in the original context\n","  # helps us computer start and end positions.\n","  offset_mapping = batch.pop('offset_mapping')\n","\n","  id_words_list_special_characters = batch.word_ids()\n","\n","  for i, offset in enumerate(offset_mapping):\n","      sample_idx = sample_mapping[i]                                                # id for identifying the row\n","      answer = answers[sample_idx]                                                  # answer associated with that id\n","      start_char = answer[\"answer_start\"][0]                                        # position character where answer starts\n","      end_char = answer[\"answer_start\"][0] + len(answer[\"answer_text\"][0])          # position character where answer finishes\n","      sequence_ids = batch.sequence_ids(i)                                         # identify question, answer, special characters (EOS, PADDING, etc)\n","\n","      # Find the start and end of the context\n","      idx = 0\n","      while sequence_ids[idx] != 1:                                                 # identify question characters or special characters\n","          idx += 1\n","      context_start = idx                                                           # identify beggining of context\n","      while sequence_ids[idx] == 1:\n","          idx += 1\n","      context_end = idx - 1                                                         # identify end of context\n","\n","      # If the answer is not fully inside the context, label is (0, 0)\n","      if offset[context_start][0] > start_char or offset[context_end][1] < end_char: # when truncating, if the first part of the context is after the answe or if the last part of the context is before the end of the answer\n","          start_positions.append(0)\n","          end_positions.append(0)\n","      else:\n","          # Otherwise it's the start and end token positions\n","          idx = context_start\n","          while idx <= context_end and offset[idx][0] <= start_char:                  # between the start of the answer\n","              idx += 1\n","          start_positions.append(idx - 1)\n","\n","          idx = context_end\n","          while idx >= context_start and offset[idx][1] >= end_char:                  # between the end of the answer\n","              idx -= 1\n","          end_positions.append(idx + 1)\n","\n","      y_sequence_loop = [0] * len(offset)\n","\n","      for index, token in enumerate(offset):\n","        if (start_positions[i]<=index)&(end_positions[i]>=index):\n","          y_sequence_loop[index] = 1\n","        if token == (0,0):\n","          y_sequence_loop[index] = -100\n","\n","      y_sequence.append(y_sequence_loop)\n","\n","  batch['labels']  = y_sequence\n","  return batch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["73cf94a854364015ae590f3cb57645f7","a4a9708aaecc4ddcb67647d2fd726cdc","5c6b8d25a3ee4dc7860015d82ac725d2","ee2150e313bd4d7a851664de1d4bd9eb","8fece496fcb64942b34b568d14bcfef6","087c39b5bf2a4592bd6c37fe2ea6cd5d","1c3e6b7899724a17bbd03989dfb735f1","d8f04ec87aff41989e32e7cf84edeaa3","b5f7b6d0d56d4419869a897d3504a8e8","867fc99a8d504d4fabd7fa586e201a89","88a899c476f4443db5c8a898472ab2b8"]},"executionInfo":{"elapsed":1363,"status":"ok","timestamp":1698683505474,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"7xcZUT2iOD4Q","outputId":"a7958e59-7a08-4709-ebf7-c53d21e71a6b"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"73cf94a854364015ae590f3cb57645f7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["val_dataset = datasets_val_filter.map(get_train_features, batched = True, remove_columns = datasets_val_filter.column_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":225,"status":"ok","timestamp":1698683506863,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"d8a2dF9NOD4R","outputId":"a8e4c1e1-3607-401f-c14c-bdbcad74b7f3"},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['input_ids', 'attention_mask', 'labels'],\n","    num_rows: 1208\n","})"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["val_dataset"]},{"cell_type":"markdown","metadata":{"id":"BSNFXowtOD4R"},"source":["##### 2.1.6.3. Load Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5iM454amOD4R"},"outputs":[],"source":["from transformers import DataCollatorForTokenClassification\n","\n","data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n","\n","from torch.optim import AdamW\n","from transformers import AutoModelForTokenClassification\n","\n","label_names = ['no answer', 'answer']\n","id2label = {'0':'no answer', '1': 'answer'}\n","label2id = {v: k for k, v in id2label.items()}\n","\n","model = AutoModelForTokenClassification.from_pretrained(checkpoint,\n","                                                       id2label=id2label,\n","                                                       label2id=label2id,).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":232,"status":"ok","timestamp":1698683542894,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"KQMsB3e5OD4R","outputId":"c7804801-4c70-4826-8ba6-621b8c0b58ba"},"outputs":[{"data":{"text/plain":["XLMRobertaForTokenClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"markdown","metadata":{"id":"PEoxpJyLOD4S"},"source":["##### 2.1.6.4. Evaluate the Train Model tn the Test Language"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CPnGQ1jrOD4S"},"outputs":[],"source":["import evaluate\n","\n","metric = evaluate.load(\"seqeval\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"miATLZZqOD4S"},"outputs":[],"source":["import numpy as np\n","\n","\n","def compute_metrics(eval_preds):\n","    logits, labels = eval_preds\n","    predictions = np.argmax(logits, axis=-1)\n","\n","    # Remove ignored index (special tokens) and convert to labels\n","    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n","    true_predictions = [\n","        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n","    return {\n","        \"precision\": all_metrics[\"overall_precision\"],\n","        \"recall\": all_metrics[\"overall_recall\"],\n","        \"f1\": all_metrics[\"overall_f1\"],\n","        \"accuracy\": all_metrics[\"overall_accuracy\"],\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R6vMP-_UOD4T"},"outputs":[],"source":["def postprocess(predictions, labels):\n","    predictions = predictions.detach().cpu().clone().numpy()\n","    labels = labels.detach().cpu().clone().numpy()\n","\n","    # Remove ignored index (special tokens) and convert to labels\n","    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n","    true_predictions = [\n","        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    return true_labels, true_predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XVnf2UCsOD4T"},"outputs":[],"source":["val_dataloader = DataLoader(\n","    val_dataset, collate_fn=data_collator, batch_size=8\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p4mkWu8pOD4T"},"outputs":[],"source":["from accelerate import Accelerator\n","\n","accelerator = Accelerator()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47553,"status":"ok","timestamp":1698683627771,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"7cxDDj0fOD4T","outputId":"36db7abf-285b-4399-fb3d-c4a3dcc8d41e"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: no answer seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: answer seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"]},{"name":"stdout","output_type":"stream","text":["{'nswer': {'precision': 0.37018425460636517, 'recall': 0.38704028021015763, 'f1': 0.37842465753424664, 'number': 571}, 'o answer': {'precision': 0.6082130965593785, 'recall': 0.6164229471316085, 'f1': 0.6122905027932961, 'number': 1778}, 'overall_precision': 0.5489787411421425, 'overall_recall': 0.5606641123882503, 'overall_f1': 0.554759898904802, 'overall_accuracy': 0.9802599703761127}\n"]}],"source":["#progress_bar = tqdm(range(num_training_steps))\n","\n","for batch in val_dataloader:\n","    batch = {key: value.to(device) for key, value in batch.items()}\n","    with torch.no_grad():\n","        outputs = model(**batch)\n","\n","    predictions = outputs.logits.argmax(dim=-1)\n","    labels = batch[\"labels\"]\n","\n","    predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n","    labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n","\n","    predictions_gathered = accelerator.gather(predictions)\n","    labels_gathered = accelerator.gather(labels)\n","\n","    true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n","    metric.add_batch(predictions=true_predictions, references=true_labels)\n","\n","results = metric.compute()\n","print(results)\n","#   progress_bar.update(1)"]},{"cell_type":"markdown","metadata":{"id":"NRpDxzATxX-A"},"source":["### 2.2. Binary Classifier"]},{"cell_type":"markdown","metadata":{"id":"FXRaVLNE4El3"},"source":["#### 2.2.1. Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I0GjGDYo4BcN"},"outputs":[],"source":["# Define function to tokenize question and documents together\n","def tokenize_function(dataset_, variable1= 'question_text', variable2= 'document_plaintext'):\n","    \"\"\"\n","    Use together question and document to create the tokenizer object\n","    that will be input of the model\n","    - We don't pad here but later in the batches.\n","    - We truncate as the length of text how the model learnt\n","    \"\"\"\n","    return tokenizer(dataset_[\"question_text\"], dataset_[\"document_plaintext\"], truncation=True, padding=\"max_length\")\n","\n","# Evaluation metric\n","metric1 = load_metric(\"f1\")\n"]},{"cell_type":"markdown","metadata":{"id":"MSIMRW8rxafk"},"source":["#### 2.2.2. Trained in Bengali, tested in Arabic and Indonesian"]},{"cell_type":"markdown","metadata":{"id":"V30xTSv24xUa"},"source":["##### 2.2.2.1. Tolkenize"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["227dd0d4cbad4d92a2c5d4ff588e77b6","51bbd504cfce439490764463672d43ae","9b6041c95b0f40bb9d28aeaa815ea06e","026f5efdea80452a8c350fb79955860e","79e6977c558a466cb5d90046038c7c13","a0080c9ba38942db93b8c9ef5fe67ff7","e4644389a8f743d3b511c0ac3ead62c4","6b123ebfdb9845ada6936faeddac6a85","4fbefc1c014b488ea558cc30741d0587","2f93465fbab540aea3a8e59808e26a04","390a5171536e423fb4fcbddd89a42121"]},"executionInfo":{"elapsed":14253,"status":"ok","timestamp":1698861962717,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"wA7lwO863s_5","outputId":"6d602e08-6c4e-46eb-bb04-138d34355901"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:datasets.fingerprint:Parameter 'function'=<function tokenize_function at 0x7fe4f3395870> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"227dd0d4cbad4d92a2c5d4ff588e77b6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/14 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# call model (it was train with arabic, bengali, and indonesian)\n","# Name of the model\n","checkpoint = \"Week 38/TRANSFORMER TRAINED MODELS/Week 38 - BERT - BENGALI\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)                         # Number of binary options\n","# Tokenizing the validation dataset\n","datasets_val_tokenize = datasets_val.map(tokenize_function, batched=True)\n","\n","# Dinamically Padding\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"markdown","metadata":{"id":"54fNoG4249OM"},"source":["##### 2.2.2.2. Load Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9BydNx-t5BWp"},"outputs":[],"source":["model = BertForSequenceClassification.from_pretrained(checkpoint).to(device)"]},{"cell_type":"markdown","metadata":{"id":"7u1LjHvb6QKO"},"source":["##### 2.2.2.3. Evaluate Train Model in the Test Language"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":189,"referenced_widgets":["c8821b6e48bc43e9bcb03db2af95767a","fc86843b0c254d41aedb316ddda15f0a","3c2013ba090c429897a528d1869fa999","123cc8a743d44694a8eb0b81b1eab953","bb5699f5b71c46cfaad5e3de18892b40","0256263aa90d4270a8594e62753b1a2c","83984dfdc63e4ec180860fb2c4a27ad4","bcc9617730ad4012884203c2fe1d6a75","16abfe0ad2704c748b804b75aa651d7a","2d34fed078de4fd89365c33979be7633","1bb94af8c03643d2b9ee4e2f28d8dc49","ed7286fe3958461d898c062e4e985ea0","c79c8fb287c94fcab8ad2fc2c6519caa","ffaa10d1f95444a9baea0facf26b8714","1d3d5f355db146c98afab72e70cef16c","ed9ba8dcde8e48a9a69b8a9199e6f4ba","558555f31fab41d0b902860f724ba767","d1bbd70260464527b1585abaaef0e781","6d3dcdca1c4540bb8d8365ebabc57fb6","a539b02359be40298b59437f5d850675","10f05885e2b24d71a441c07d5a854f86","7ec01c519628447698d508edf233dddd","b6e43efbb7bd4bff803d8c514ca77ea2","d7a413158b5d40e6afd87807fe317e78","054fd79cb23f4361b7b8456e78d7c2da","246e6f598a9e48158717c78ae066c966","ced027cc277847ecba25ad0700898ab3","c6607b631f444e2d8c0b0d8e4fa79057","40db335f128a48b9910a3f07a354f97e","eb93d181247a45d689e80159e08c9637","a3c11ad80658459c85670fd6942dc447","b26e75154a9e435abf9e035d0c8c37e3","86d5d03b68424daeaa8e6e22bb9102b5"]},"executionInfo":{"elapsed":1399072,"status":"ok","timestamp":1698398956960,"user":{"displayName":"Alex YE","userId":"10586116328910308711"},"user_tz":-120},"id":"4B0pZ06dn5yf","outputId":"561a3de4-86c7-4b81-af08-f71448f9169b"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:datasets.fingerprint:Parameter 'function'=<function tokenize_function at 0x7920653da170> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c8821b6e48bc43e9bcb03db2af95767a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/14 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ed7286fe3958461d898c062e4e985ea0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/14 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["F1 score for arabic: 0.6640378548895899\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b6e43efbb7bd4bff803d8c514ca77ea2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/14 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["F1 score for indonesian: 0.6658270361041142\n"]}],"source":["# Evaluate for each language\n","for language in ['arabic', 'indonesian']:\n","    datasets_val_tokenize_filter = datasets_val_tokenize.filter(lambda example: example[\"language\"] == language)\n","\n","    # Manual evaluation\n","    model.eval()  # Put the model in evaluation mode\n","    logits_list = []\n","    with torch.no_grad():  # Deactivate autograd engine to reduce memory usage and speed up computations\n","        for i in range(len(datasets_val_tokenize_filter)):\n","            instance = datasets_val_tokenize_filter[i]\n","            inputs = {key: torch.tensor(val).unsqueeze(0) for key, val in instance.items() if key in ['input_ids', 'attention_mask']}\n","            outputs = model(**inputs)\n","            logits_list.append(outputs.logits)\n","\n","    # Convert logits list to numpy array and get the predicted labels\n","    predicted_labels = torch.softmax(torch.cat(logits_list), dim=-1).argmax(dim=-1).numpy()\n","\n","    # Calculate F1 score\n","    true_labels = [example['label'] for example in datasets_val_tokenize_filter]\n","    print(f'F1 score for {language}:', f1_score(true_labels, predicted_labels, average='micro'))  # Specify the appropriate averaging method"]},{"cell_type":"markdown","metadata":{"id":"lmG22IOa3tYP"},"source":["#### 2.2.3. Trained in Indonesian, tested in Arabic and Bengali"]},{"cell_type":"markdown","metadata":{"id":"C9IY7JZXImEP"},"source":["##### 2.2.3.1. Tolkenize"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["dfb34e00ef244e7fafb2d5dba9b5f626","40f12159ff6d4cf6b01ac11454930785","c85b6e98ec5d416f8e2375ea6d40c892","9748c868a7c34ee289cf9702061ea357","9bee1e215ac9452391558ebd7fcf0299","3044485d9fd14bd19a62fb0959c8c578","22ddf44933784e9cafa4ff510e121b91","da89468c397d4efd8c790cd3ca2843e8","7166ee14e0c54e13889bece5dac3dccf","8f566854e0054beeb6d092b5af853ec7","043bf94106504c7c9d2f9cac11cc70b1"]},"executionInfo":{"elapsed":34737,"status":"ok","timestamp":1698863195330,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"674jMDDvImEY","outputId":"d988bf00-7a62-4573-c816-7e4c4de15b47"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dfb34e00ef244e7fafb2d5dba9b5f626","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/14 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# call model (it was train with arabic, bengali, and indonesian)\n","# Name of the model\n","checkpoint = \"Week 38/TRANSFORMER TRAINED MODELS/Week 38 - BERT - INDONESIAN\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)                         # Number of binary options\n","# Tokenizing the validation dataset\n","datasets_val_tokenize = datasets_val.map(tokenize_function, batched=True)\n","\n","# Dinamically Padding\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"markdown","metadata":{"id":"Ukr0PHZ_ImEZ"},"source":["##### 2.2.3.2. Load Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j0R4w44sImEZ"},"outputs":[],"source":["model = BertForSequenceClassification.from_pretrained(checkpoint).to(device)"]},{"cell_type":"markdown","metadata":{"id":"Vo1Lroe1ImEa"},"source":["##### 2.2.3.3. Evaluate Train Model in the Test Language"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":148,"referenced_widgets":["b043ed7917be4b3e9df3a7a4865656a4","509d057770bd43f38a5ea8d9f3bbc2a3","17c4a4707d474fa395306edae9a8500c","3023a079811e49a0a13ec8f9ca4a5d65","de965a46ae8d4643a3cecdd136b97523","2723bbc8f3d34aa09a6cc1e32776debd","925a83e9773d4c3b9eb42c6940b9e2ea","d4d8917ad89048d592d3a11ef8cff7b1","ca9550f9ede84b0ca782c82c1bdbe572","0d55cf1aa40f4b99bdf10b6f8075e0b2","5a98e7dffb4446bcb39b06964a3263e6","ac5aac77c62f4b359f77d888e6625d52","1dbddf80dc5f41a482365ae4b64d559e","3dbec7e4727940cba69bbb85842835c1","528c3c4e5bd74fa48ae42f2d342f8cfc","77be11620384465ea1d488e0c6c45786","5d97608cd29b441cb2f6bbbb7d7cfbda","61d5dd0ea8a8438a8f64cd9c038eb30c","6559919b133a4110ae5a9650870912b7","aef3e39f49914b319b833dbb48c21754","2ac600a3bebd4608884465f0c3607ed1","19a2c93ba88741e9b14536f261b43604","64b5749a5c344093a3a3e7b83b73a910","0de58f2ea4a249e98e90082fe72bd001","59a3d05f60ea42a9afefb51369fc0667","0453ee0e2c444009be54051e4dc9f1c8","eb865440f10d499c8d80ee40d9d48e56","a2ed503785b543ad929c6d769e034aee","a70e85a85f1e4bb88f210a2009dbcd07","48885782fcae451c8355ce51fa86d89c","0976205dfd7f42c4940a074e7e025784","4081b86fe36e4e73a81befa78b5ae7f1","31eb1e3965794c9c9e14e1357ad5e408"]},"executionInfo":{"elapsed":20596,"status":"ok","timestamp":1698343489816,"user":{"displayName":"Alex Ye","userId":"17265174233791265914"},"user_tz":-120},"id":"WhA4jAyEA-4n","outputId":"5c3ef3e6-4243-4662-c2ba-cda4c70ec37b"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b043ed7917be4b3e9df3a7a4865656a4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/14 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ac5aac77c62f4b359f77d888e6625d52","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/14 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["F1 score for arabic: 0.7066246056782335\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"64b5749a5c344093a3a3e7b83b73a910","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/14 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["F1 score for bengali: 0.6339285714285714\n"]}],"source":["# Evaluate for each language\n","for language in ['arabic', 'bengali']:\n","    datasets_val_tokenize_filter = datasets_val_tokenize.filter(lambda example: example[\"language\"] == language)\n","\n","    # Manual evaluation\n","    model.eval()  # Put the model in evaluation mode\n","    logits_list = []\n","    with torch.no_grad():  # Deactivate autograd engine to reduce memory usage and speed up computations\n","        for i in range(len(datasets_val_tokenize_filter)):\n","            instance = datasets_val_tokenize_filter[i]\n","            inputs = {key: torch.tensor(val).unsqueeze(0) for key, val in instance.items() if key in ['input_ids', 'attention_mask']}\n","            outputs = model(**inputs)\n","            logits_list.append(outputs.logits)\n","\n","    # Convert logits list to numpy array and get the predicted labels\n","    predicted_labels = torch.softmax(torch.cat(logits_list), dim=-1).argmax(dim=-1).numpy()\n","\n","    # Calculate F1 score\n","    true_labels = [example['label'] for example in datasets_val_tokenize_filter]\n","    print(f'F1 score for {language}:', f1_score(true_labels, predicted_labels, average='micro'))  # Specify the appropriate averaging method"]},{"cell_type":"markdown","metadata":{"id":"L8ugVBGk35EA"},"source":["#### 2.2.4. Trained in Arabic, tested in Bengali and Indonesian"]},{"cell_type":"markdown","metadata":{"id":"Kvw6V-TeJenn"},"source":["##### 2.2.3.1. Tolkenize"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["9676edc9c1824e5d90b3f3af53864d1c","8700003705174b49846082c808d4f1e2","a4913da005534fba86e89e2562031172","b2d52cd13b2b43d893ecf10fb5ac9380","dc7586cb989043579d6dda4f555ba88e","65da8cdb8af24c8890027ae2bd7add5a","b48e9dcb992c45c88a4119c178983ba4","bbf94d760a464561aaedb730fa15d352","ce31df158b984ea591f1e29322443f0c","2e1b4c8f145f4d6f84ebf70f43113b06","43e0bdf86fd54a8e98b9e0f14abdc08c"]},"executionInfo":{"elapsed":11833,"status":"ok","timestamp":1698863402160,"user":{"displayName":"Alan Miguel Forero Sanabria","userId":"15051656969276578416"},"user_tz":-60},"id":"ma12GJVgJeoA","outputId":"0364f322-9297-47ad-8e6f-8f95445b7159"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9676edc9c1824e5d90b3f3af53864d1c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/14 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# call model (it was train with arabic, bengali, and indonesian)\n","# Name of the model\n","checkpoint = \"Week 38/TRANSFORMER TRAINED MODELS/Week 38 - BERT - ARABIC\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)                         # Number of binary options\n","# Tokenizing the validation dataset\n","datasets_val_tokenize = datasets_val.map(tokenize_function, batched=True)\n","\n","# Dinamically Padding\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"markdown","metadata":{"id":"s0HLubz7JeoA"},"source":["##### 2.2.3.2. Load Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FeExNkzXJeoB"},"outputs":[],"source":["model = BertForSequenceClassification.from_pretrained(checkpoint).to(device)"]},{"cell_type":"markdown","metadata":{"id":"9PKuRurnJeoB"},"source":["##### 2.2.3.3. Evaluate Train Model in the Test Language"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":185,"referenced_widgets":["852e6e7569ea42c7abe5216e4282b57f","b64bd1cdaae3471693bf1f5596bf297b","2433b68100c346aba79c7664f903b812","55e2757e61814c73bd1a85a97b3480e7","4e5c4528ac424e00874a4836db2ed12a","533ae98924fe4f2ba48e681843183350","453b821484dd46a3838951ccd3ad379e","bc126ee008954aeb95c4e7acaae728bf","54a708b6745b4d2f8b0a0cbdc4b1e101","97663b3ae7a34bdea16132641f4b1909","7aa654910ff14b649a5637615c905625","8e858d53776642c2a24db5cff47bd368","d691b0ad34c0488c93e23903d0f98cd7","6695e63265764284b557a0a61e170a2c","91f918af5fde4ecf85b2767ccf856b69","81f483f929504ad5a14598520ce650af","b39dcd5cd1b946a590aa46cda245b258","0e8481e1103846e79a0aa41311947d96","d352205b3f1442d9abf8f8877af1c3a9","f9a132e648994f4e87d77c9ae7048d61","949793f9e8d94cecaa0ebaa88d119b02","8108eff4a14142fda88f9946d8f378e1","82161b57b55f47bc8c90a7da5c0c6298","ede5cc34c70447628683043f9b36039f","9392e659ca78469f8ec434eb8a5e0483","2afda7b6260148c091806896c4290f61","f910b440a4ac4f71a248575edfced691","c54ac65cbf6c429791d69b684c0dbfb0","82511e926bcb40c3a66936d04c56e7d4","204e769cae3549259f5f8d5565f4bc56","24e591ed96d7438490d3adb234c928ca","53d204199bc04a808ba435e6377a8176","4b27e2196c784884a4967b05704950d2"]},"executionInfo":{"elapsed":2368818,"status":"ok","timestamp":1698867273738,"user":{"displayName":"Alex Ye","userId":"17265174233791265914"},"user_tz":-60},"id":"9KvASZRhBCgD","outputId":"b1a1a6c2-a702-4579-9ada-4780abe934d9"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:datasets.fingerprint:Parameter 'function'=<function tokenize_function at 0x7a05fb77add0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"852e6e7569ea42c7abe5216e4282b57f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/14 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e858d53776642c2a24db5cff47bd368","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/14 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["F1 score for bengali: 0.7321428571428571\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"82161b57b55f47bc8c90a7da5c0c6298","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/14 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["F1 score for indonesian: 0.8295549958018472\n"]}],"source":["# Define the languages list\n","languages = ['bengali', 'indonesian']\n","\n","# Load model and tokenizer\n","model_directory = \"/content/drive/MyDrive/NLP/Binary_Arabic\"\n","model = BertForSequenceClassification.from_pretrained(model_directory)\n","tokenizer = AutoTokenizer.from_pretrained(model_directory)\n","\n","# Define function to tokenize question and documents together\n","def tokenize_function(examples):\n","    return tokenizer(examples[\"question_text\"], examples[\"document_plaintext\"], padding=\"max_length\", truncation=True, max_length=512)\n","\n","# Tokenizing the validation dataset\n","datasets_val_tokenize = datasets_val.map(tokenize_function, batched=True)\n","\n","# Evaluate for each language\n","for language in languages:\n","    datasets_val_tokenize_filter = datasets_val_tokenize.filter(lambda example: example[\"language\"] == language)\n","\n","    # Manual evaluation\n","    model.eval()  # Put the model in evaluation mode\n","    logits_list = []\n","    with torch.no_grad():  # Deactivate autograd engine to reduce memory usage and speed up computations\n","        for i in range(len(datasets_val_tokenize_filter)):\n","            instance = datasets_val_tokenize_filter[i]\n","            inputs = {key: torch.tensor(val).unsqueeze(0) for key, val in instance.items() if key in ['input_ids', 'attention_mask']}\n","            outputs = model(**inputs)\n","            logits_list.append(outputs.logits)\n","\n","    # Convert logits list to numpy array and get the predicted labels\n","    predicted_labels = torch.softmax(torch.cat(logits_list), dim=-1).argmax(dim=-1).numpy()\n","\n","    # Calculate F1 score\n","    true_labels = [example['label'] for example in datasets_val_tokenize_filter]\n","    print(f'F1 score for {language}:', f1_score(true_labels, predicted_labels, average='micro'))  # Specify the appropriate averaging method"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["0jDRMwJFG31h","S5n302rlIblM","wjs9ApFwMrog","VkrY-lgQMv-J","zrOaTX15Ie8s","xQkFMJpJKTij","kU3xBGtw_sOD","VUDVf7zBaL-S","xfOXaPOjvvig","ZEMfGVtxmACX","-wp9hHE8GeS7","gpmTCu0jGgiY","MFYc-GVKHA3h","S5M3SCbeH7e5","Q61ORRASmzFz","3vGbPF31mzGR","IRNOE_AgmzGT","GenDAacLmzGY","xdRaZ9avmzGb","fvnp7IqknhOf","UcFf2oDbMO6s","cMuQjO52MO6u","XUozuRMFMO6v","VQUVttF3MO6w","G8MPA7dPntAl","0N62TwnGPYYe","NAWkAh24PYYi","HUsVBScuPYYo","baXV2NRSPYYr","wXHtGCc-n0nT","CJeJtnAyNWz5","LbD7tvk_NW0E","0dwWsXPxNW0F","hUVuYzIrNW0G","BguBSFC_oAAy","dpwqMnOeOD4O","m7WrecSMOD4P","BSNFXowtOD4R","PEoxpJyLOD4S","NRpDxzATxX-A","FXRaVLNE4El3","MSIMRW8rxafk","V30xTSv24xUa","54fNoG4249OM","7u1LjHvb6QKO","lmG22IOa3tYP","C9IY7JZXImEP","Ukr0PHZ_ImEZ","Vo1Lroe1ImEa","L8ugVBGk35EA","Kvw6V-TeJenn"],"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"026f5efdea80452a8c350fb79955860e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f93465fbab540aea3a8e59808e26a04","placeholder":"​","style":"IPY_MODEL_390a5171536e423fb4fcbddd89a42121","value":" 14/14 [00:10&lt;00:00,  2.02ba/s]"}},"04331d08a3c84bd68eec03f877a0242e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8a4045cf2a24494b07f38d6e3c589dd","placeholder":"​","style":"IPY_MODEL_7177d00a257e4b66845114c76ad4198c","value":" 2/2 [00:03&lt;00:00,  1.58s/it]"}},"043bf94106504c7c9d2f9cac11cc70b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05783cf32c6b42d4b0428557191ecdc9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0780a3f208d640e7b4051f92fd8c7598":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08fbd243439b4b638ee4fd62d2ac9704":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0db7e52209fc48ce836af0fc882cc4d2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1108d5d3a66649e481f2ddf82ce811da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e9f18c2dbb8498aaa245b0dac81e95d","placeholder":"​","style":"IPY_MODEL_8bd0089169f449aba57d724d2f4b5c9b","value":"Downloading: 100%"}},"12ff64b2010340bb8c323a19c14f673d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1868226cbf0f4cbeaf6c4dd07b07fafe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b6c607765e9463db27738ce6b260edd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ff51268d3e9401fadf9397c6cc23ff8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"227dd0d4cbad4d92a2c5d4ff588e77b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_51bbd504cfce439490764463672d43ae","IPY_MODEL_9b6041c95b0f40bb9d28aeaa815ea06e","IPY_MODEL_026f5efdea80452a8c350fb79955860e"],"layout":"IPY_MODEL_79e6977c558a466cb5d90046038c7c13"}},"22ddf44933784e9cafa4ff510e121b91":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"246f97f515044eed816274ffc6892e8d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25d6f5a6dea44638bc8af6b9e591fab5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28ffa0c40b724540a8c15291dcbdf95a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b0df9c36bed045d0808a22b00c221258","IPY_MODEL_f07a6c26a1254b23971a567066056557","IPY_MODEL_ef95d4b96ddd40558f6c28479da456b6"],"layout":"IPY_MODEL_7d1b4c73204c4f70b221bc40694cb27f"}},"2c292c3171c645abb90b41f74b912eb3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ce076baba8a4848a9bf34b7baba6c50":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08fbd243439b4b638ee4fd62d2ac9704","placeholder":"​","style":"IPY_MODEL_fb6e89fe7dd2447aa6ea06bd1c9834ad","value":"Extracting data files: 100%"}},"2e1b4c8f145f4d6f84ebf70f43113b06":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f93465fbab540aea3a8e59808e26a04":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3044485d9fd14bd19a62fb0959c8c578":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3147f9a63b0d4eab95caca8ce33811fa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34292ae879ff42a8ac47b454c8e8f58e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a61343fc1549444fa3c78cf519b520ee","max":7485054,"min":0,"orientation":"horizontal","style":"IPY_MODEL_70db074ab7d3418abcf86018a94bfdc3","value":7485054}},"35402735f0aa4bc9b75e4d026a341957":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_691ae831a0a846b9836575ac6b138d36","placeholder":"​","style":"IPY_MODEL_1b6c607765e9463db27738ce6b260edd","value":" 7.49M/7.49M [00:00&lt;00:00, 16.4MB/s]"}},"37752254dc604e06ab5f9cb11a3805f1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"390a5171536e423fb4fcbddd89a42121":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c5554b2ce1c488f898f621b20a96793":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e9f18c2dbb8498aaa245b0dac81e95d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"403dd3c7c8794f33b31b8af353af1f19":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40f12159ff6d4cf6b01ac11454930785":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3044485d9fd14bd19a62fb0959c8c578","placeholder":"​","style":"IPY_MODEL_22ddf44933784e9cafa4ff510e121b91","value":"100%"}},"43e0bdf86fd54a8e98b9e0f14abdc08c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b16517687384923ad7a6e14dd1d10ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b050c6e337f14a60930d33780f3895c7","IPY_MODEL_bee845de377a4585b1be893583537201","IPY_MODEL_04331d08a3c84bd68eec03f877a0242e"],"layout":"IPY_MODEL_6e06b39e956c435cb4b273e20b50f5de"}},"4fbefc1c014b488ea558cc30741d0587":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"51bbd504cfce439490764463672d43ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0080c9ba38942db93b8c9ef5fe67ff7","placeholder":"​","style":"IPY_MODEL_e4644389a8f743d3b511c0ac3ead62c4","value":"100%"}},"523734ee2de14215b7ad442849f1ff75":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12ff64b2010340bb8c323a19c14f673d","placeholder":"​","style":"IPY_MODEL_870bdbadc54a47cb8e251126c31e1ca6","value":" 2/2 [00:00&lt;00:00, 40.47it/s]"}},"64c64598ba6a4d3596d782b152f01b37":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37752254dc604e06ab5f9cb11a3805f1","placeholder":"​","style":"IPY_MODEL_3147f9a63b0d4eab95caca8ce33811fa","value":" 2.47k/2.47k [00:00&lt;00:00, 123kB/s]"}},"65da8cdb8af24c8890027ae2bd7add5a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68d9f4b5b4774477817ce4e314c76670":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a93e40e9c5b84b44b6d507a3f1cdd76f","max":2470,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e2b023eaec954262b06deb55e745198d","value":2470}},"691ae831a0a846b9836575ac6b138d36":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a2c8e713d0b43b2844b26e4b3c16ffe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2ce076baba8a4848a9bf34b7baba6c50","IPY_MODEL_dfe3357fa68848c38cf1ec7a2d791b37","IPY_MODEL_523734ee2de14215b7ad442849f1ff75"],"layout":"IPY_MODEL_403dd3c7c8794f33b31b8af353af1f19"}},"6b123ebfdb9845ada6936faeddac6a85":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d19cefd1ced485fa637c363700c2b63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6e06b39e956c435cb4b273e20b50f5de":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70db074ab7d3418abcf86018a94bfdc3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7166ee14e0c54e13889bece5dac3dccf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7177d00a257e4b66845114c76ad4198c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72e481e3c1be47529e52c34df6a2593c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1108d5d3a66649e481f2ddf82ce811da","IPY_MODEL_68d9f4b5b4774477817ce4e314c76670","IPY_MODEL_64c64598ba6a4d3596d782b152f01b37"],"layout":"IPY_MODEL_939eab7a92ea4335b412107c0db7b1c3"}},"78184cb68e4749eba08bb2acf87bc99d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7dc0037eebee4e0ba948972f15a37151","IPY_MODEL_34292ae879ff42a8ac47b454c8e8f58e","IPY_MODEL_35402735f0aa4bc9b75e4d026a341957"],"layout":"IPY_MODEL_9008002bef4c4674a8d162a00ac5f9cc"}},"79e6977c558a466cb5d90046038c7c13":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d1b4c73204c4f70b221bc40694cb27f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7dc0037eebee4e0ba948972f15a37151":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d3faab44c4c45ec8d3f6095271e90ec","placeholder":"​","style":"IPY_MODEL_e65c044095f64ad8a9f7b244ce33fe65","value":"Downloading data: 100%"}},"8700003705174b49846082c808d4f1e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_65da8cdb8af24c8890027ae2bd7add5a","placeholder":"​","style":"IPY_MODEL_b48e9dcb992c45c88a4119c178983ba4","value":"100%"}},"870bdbadc54a47cb8e251126c31e1ca6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8bd0089169f449aba57d724d2f4b5c9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f566854e0054beeb6d092b5af853ec7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9008002bef4c4674a8d162a00ac5f9cc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"939eab7a92ea4335b412107c0db7b1c3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9676edc9c1824e5d90b3f3af53864d1c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8700003705174b49846082c808d4f1e2","IPY_MODEL_a4913da005534fba86e89e2562031172","IPY_MODEL_b2d52cd13b2b43d893ecf10fb5ac9380"],"layout":"IPY_MODEL_dc7586cb989043579d6dda4f555ba88e"}},"9748c868a7c34ee289cf9702061ea357":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f566854e0054beeb6d092b5af853ec7","placeholder":"​","style":"IPY_MODEL_043bf94106504c7c9d2f9cac11cc70b1","value":" 14/14 [00:10&lt;00:00,  1.28ba/s]"}},"9b6041c95b0f40bb9d28aeaa815ea06e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b123ebfdb9845ada6936faeddac6a85","max":14,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4fbefc1c014b488ea558cc30741d0587","value":14}},"9bee1e215ac9452391558ebd7fcf0299":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d3faab44c4c45ec8d3f6095271e90ec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0080c9ba38942db93b8c9ef5fe67ff7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4913da005534fba86e89e2562031172":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbf94d760a464561aaedb730fa15d352","max":14,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ce31df158b984ea591f1e29322443f0c","value":14}},"a61343fc1549444fa3c78cf519b520ee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a851ee6e72e7428ea59789e55224fe0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a93e40e9c5b84b44b6d507a3f1cdd76f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b050c6e337f14a60930d33780f3895c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1868226cbf0f4cbeaf6c4dd07b07fafe","placeholder":"​","style":"IPY_MODEL_a851ee6e72e7428ea59789e55224fe0d","value":"Downloading data files: 100%"}},"b0df9c36bed045d0808a22b00c221258":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05783cf32c6b42d4b0428557191ecdc9","placeholder":"​","style":"IPY_MODEL_3c5554b2ce1c488f898f621b20a96793","value":"Downloading data: 100%"}},"b2d52cd13b2b43d893ecf10fb5ac9380":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e1b4c8f145f4d6f84ebf70f43113b06","placeholder":"​","style":"IPY_MODEL_43e0bdf86fd54a8e98b9e0f14abdc08c","value":" 14/14 [00:10&lt;00:00,  1.28ba/s]"}},"b48e9dcb992c45c88a4119c178983ba4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bbf94d760a464561aaedb730fa15d352":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bee845de377a4585b1be893583537201":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0db7e52209fc48ce836af0fc882cc4d2","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1ff51268d3e9401fadf9397c6cc23ff8","value":2}},"c85b6e98ec5d416f8e2375ea6d40c892":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_da89468c397d4efd8c790cd3ca2843e8","max":14,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7166ee14e0c54e13889bece5dac3dccf","value":14}},"ce31df158b984ea591f1e29322443f0c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d8a4045cf2a24494b07f38d6e3c589dd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da89468c397d4efd8c790cd3ca2843e8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc7586cb989043579d6dda4f555ba88e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfb34e00ef244e7fafb2d5dba9b5f626":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_40f12159ff6d4cf6b01ac11454930785","IPY_MODEL_c85b6e98ec5d416f8e2375ea6d40c892","IPY_MODEL_9748c868a7c34ee289cf9702061ea357"],"layout":"IPY_MODEL_9bee1e215ac9452391558ebd7fcf0299"}},"dfe3357fa68848c38cf1ec7a2d791b37":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0780a3f208d640e7b4051f92fd8c7598","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6d19cefd1ced485fa637c363700c2b63","value":2}},"e2b023eaec954262b06deb55e745198d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e4644389a8f743d3b511c0ac3ead62c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e65c044095f64ad8a9f7b244ce33fe65":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e8cbecc4e26c4878854d1d3b453cccf8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef95d4b96ddd40558f6c28479da456b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_246f97f515044eed816274ffc6892e8d","placeholder":"​","style":"IPY_MODEL_e8cbecc4e26c4878854d1d3b453cccf8","value":" 71.6M/71.6M [00:01&lt;00:00, 79.7MB/s]"}},"f07a6c26a1254b23971a567066056557":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_25d6f5a6dea44638bc8af6b9e591fab5","max":71610080,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2c292c3171c645abb90b41f74b912eb3","value":71610080}},"fb6e89fe7dd2447aa6ea06bd1c9834ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
